[{"title":"Prometheus如何使用 Push 方式采集目标服务器数据","date":"2023-12-17T12:21:31.180Z","path":"2023/12/17/2023/云原生/Prometheus如何使用 Push 方式采集目标服务器数据/","text":"公众号「架构成长指南」，专注于生产实践、云原生、分布式系统、大数据技术分享 在上篇主要介绍了从零开始：使用Prometheus与Grafana搭建监控系统，我们了解了Prometheus采集数据主要是采用Pull模式，即主动拉取模式，这种方式虽然简单，但是有一定限制，比如服务器A部署在边缘端与Prometheus部署在云端，两者网络不通，因此不能采用Pull模式。 那么如何获取服务器 A 的指标？答案就是采用Pushgateway，这里Pushgateway充当了一个桥接的作用，把Pushgateway服务暴漏一个公网地址，然后服务器 A 与Prometheus都能连接即可。服务器 把数据 Push到Pushgateway，然后 Prometheus 去 Pushgateway 上定时 pull数据即可。 下面分享一下如何使用Pushgateway如何采集远程节点数据指标。 下载1docker pull prom/pushgateway:v1.5.1 启动1docker run --name pushgateway -d -p 9091:9091 prom/pushgateway:v1.5.1 访问http://localhost:9091/metrics查看是否启动成功，可以看到Pushgateway自身也带了一些指标 边缘服务器配置下载node-exporter1wget https://github.com/prometheus/node_exporter/releases/download/v1.5.0/node_exporter-1.5.0.linux-arm64.tar.gz 下载完成以后执行tar -xvf node_exporter-1.5.0.linux-arm64.tar.gz &amp;&amp; cd node_exporter-1.5.0.linux-arm64进行解压 解压完成以后，执行./node_exporter进行简单验证， 看到以上信息则启动成功，通过浏览器进行访问http://ip:9100/metrics，可以看到以下指标 安装node-exporter由于直接启动node-exporter关闭窗口此进程就会挂掉，因此可以采用systemctl方式进行配置 执行mv node_exporter //usr/local/移动node_exporter文件 在/usr/lib/systemd/system/目录，创建node_exporter.service文件，内容如下，ExecStart指向的就是node_exporter执行文件 12345678910cat &lt;&lt;EOF &gt; /usr/lib/systemd/system/node_exporter.service[Unit]Description=Node Exporter[Service]ExecStart=/usr/local/node_exporterRestart=on-failure[Install]WantedBy=multi-user.targetEOF 执行systemctl daemon-reload 执行systemctl start node_exporter启动node_exporter 执行netstat -aon|grep 9100查看9100是否启动成功 边缘端指标上报由于node-exporter只提供的数据，默认是由prometheus进行pull的方式来获取指标数据，而我们需要主动push数据到Pushgateway，所以这里需要增加shell脚本，先获取node-exporter数据，然后在调用Pushgateway接口进行push，以下为推送语句 PushgatewayIP: 10.211.55.2 边缘服务器IP:10.211.55.6 1curl 10.211.55.6:9100/metrics|curl --data-binary @- http://10.211.55.2:9091/metrics/job/agent-server/instance/10.211.55.6/hostname/边缘服务器 手动执行以下脚本，并访问Pushgateway查看是否有对应数据 可以看到数据已上传 虽然以上脚本没问题，但是还需要定时执行才行，所以需要编写shell脚本，并通过crontab进行调用 创建shell脚本 12345cat &lt;&lt;EOF &gt; /etc/cron.d/propushgateway.sh#!/bin/bashcurl 10.211.55.6:9100/metrics|curl --data-binary @- http://10.211.55.2:9091/metrics/job/agent-server/instance/hostname/10.211.55.6date&gt;&gt; /tmp/date.txtEOF 分配文件执行权限 1chmod 777 /etc/cron.d/propushgateway.sh 配置crontab任务，10s执行一次，由于crontab只支持到分，所以采用采用以下方式配置 12345678crontab -e* * * * * /etc/cron.d/propushgateway.sh* * * * * sleep 10; /etc/cron.d/propushgateway.sh* * * * * sleep 20; /etc/cron.d/propushgateway.sh* * * * * sleep 30; /etc/cron.d/propushgateway.sh* * * * * sleep 40; /etc/cron.d/propushgateway.sh* * * * * sleep 50; /etc/cron.d/propushgateway.sh 查看执行日志tail -f /var/log/cron，可以看到10s执行一次 修改prometheus配置文件在prometheus.yml文件中增加如下配置 1234567- job_name: &#x27;AgentServer&#x27; # Override the global default and scrape targets from this job every 5 seconds. honor_labels: false static_configs: - targets: [&#x27;10.211.55.2:9091&#x27;] labels: pushgateway_instance: agent-server ##这里必须加这边标签过滤，不然采集的是pushGateway数据 增加完成以后重启prometheus 1docker restart prometheus 启动完成以后访问prometheus地址，查看Pushgateway的target已经生效 通过Grafana查看数据","tags":[{"name":"Prometheus","slug":"Prometheus","permalink":"https://dongweizhao.github.io/tags/Prometheus/"},{"name":"监控告警","slug":"监控告警","permalink":"https://dongweizhao.github.io/tags/%E7%9B%91%E6%8E%A7%E5%91%8A%E8%AD%A6/"}]},{"title":"从零开始：使用Prometheus与Grafana搭建监控系统","date":"2023-12-17T06:13:37.043Z","path":"2023/12/17/2023/云原生/从零开始：使用Prometheus与Grafana搭建监控系统/","text":"公众号「架构成长指南」，专注于生产实践、云原生、分布式系统、大数据技术分享 Prometheus介绍Prometheus是一款开源的监控系统，主要用于收集、存储和查询时间序列数据，以便于对系统进行监控和分析。 Prometheus的架构由四个主要组件组成： Prometheus Server ：Prometheus Server是Prometheus的核心组件，主要负责从各个目标（target）中收集指标（metrics）数据，并对这些数据进行存储、聚合和查询。 Client Libraries ：Prometheus提供了多种客户端库，用于在应用程序中嵌入Prometheus的指标收集功能。 Exporters ：Exporters是用于将第三方系统的监控数据导出为Prometheus格式的组件。Prometheus支持多种Exporters，例如Node Exporter、MySQL Exporter、HAProxy Exporter等。 Alertmanager：Alertmanager是Prometheus的告警组件，用于根据用户定义的规则对监控数据进行告警。 同时Prometheus有以下优点 灵活的数据模型：Prometheus采用的是key-value对的形式存储指标数据，每个指标都可以包含多个标签（labels），这样可以更加灵活地描述指标数据 高效的存储和查询：Prometheus使用自己的时间序列数据库，可以高效地存储和查询大量的指标数据。 强大的可视化和告警功能：Prometheus提供了Web界面和API，可以方便地展示和查询监控数据。 可扩展性强：Prometheus的架构非常灵活，可以根据需要选择合适的组件进行配置。 CNCF的成员项目：Prometheus作为CNCF的项目之一，得到了广泛的关注和支持，并且得到了来自全球各地的贡献者的积极参与和开发。 Prometheus介绍下面就Prometheus基于本地环境进行监控报警进行讲解 下载1docker pull prom/prometheus:v2.43.0 配置创建文件夹data 创建配置文件prometheus.yml，可以根据需要进行配置 12345678910111213141516171819global: scrape_interval: 15s # By default, scrape targets every 15 seconds. # Attach these labels to any time series or alerts when communicating with # external systems (federation, remote storage, Alertmanager). external_labels: monitor: &#x27;codelab-monitor&#x27;# A scrape configuration containing exactly one endpoint to scrape:# Here it&#x27;s Prometheus itself.scrape_configs: # The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config. - job_name: &#x27;prometheus&#x27; # Override the global default and scrape targets from this job every 5 seconds. scrape_interval: 5s static_configs: - targets: [&#x27;localhost:9090&#x27;] 因为路径过长，创建软链目录/data/prometheus 1ln -s /Users/weizhao.dong/Documents/soft/prometheus /data/prometheus 启动1docker run --name prometheus -d -p 9090:9090 -v /data/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml -v /data/prometheus:/prometheus prom/prometheus:v2.43.0 Grafana安装下载1docker pull grafana/grafana-enterprise:8.5.22 启动1docker run -d --name=grafana -p 3000:3000 grafana/grafana-enterprise:8.5.22 配置数据源添加prometheus数据源 Linux服务器资源监控下载node-exporter选择指定版本，并下载 1wget https://github.com/prometheus/node_exporter/releases/download/v1.5.0/node_exporter-1.5.0.linux-arm64.tar.gz 下载解压执行node_exporter文件暴漏9100端口，即可采集到监控信息 安装node-exporter由于直接启动node-exporter关闭窗口此进程就会挂掉，不能满足需求，因此可以采用systemctl方式进行配置 在/usr/lib/systemd/system/目录，创建node_exporter.service文件，内容如下，ExecStart指向的就是node_exporter执行文件 12345678[Unit]Description=Node Exporter[Service]ExecStart=/usr/local/node_exporterRestart=on-failure[Install]WantedBy=multi-user.target 执行systemctl daemon-reload 执行systemctl start node_exporter启动node_exporter 执行netstat -aon|grep 9100查看9100是否启动成功 修改prometheus配置文件增加以下任务，5s采集一次，这种方式属于Promethues的Pull 模式，即主动发起请求拉取目标数据 12345- job_name: &#x27;linux&#x27; # Override the global default and scrape targets from this job every 5 seconds. scrape_interval: 5s static_configs: - targets: [&#x27;10.211.55.4:9100&#x27;] 重启prometheus1docker restart prometheus Grafana文件配置访问grafana下载node_export配置文件 点击进去，点击右边的DownloadJson文件进行下载 文件下载以后导入到Grafana 导入完成以后，可以看到相关数据已采集。 总结在本文中，我们介绍了什么是Prometheus，如何安装Prometheus，以及使用Prometheus的Pull(拉取)模式来采集Linux服务器资源，并在Grafana进行展现。","tags":[{"name":"Prometheus","slug":"Prometheus","permalink":"https://dongweizhao.github.io/tags/Prometheus/"},{"name":"架构成长指南","slug":"架构成长指南","permalink":"https://dongweizhao.github.io/tags/%E6%9E%B6%E6%9E%84%E6%88%90%E9%95%BF%E6%8C%87%E5%8D%97/"},{"name":"系统监控","slug":"系统监控","permalink":"https://dongweizhao.github.io/tags/%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%8E%A7/"},{"name":"Prometheus入门","slug":"Prometheus入门","permalink":"https://dongweizhao.github.io/tags/Prometheus%E5%85%A5%E9%97%A8/"}]},{"title":"基于K8S私有化交付要注意几点问题","date":"2023-12-17T05:16:20.905Z","path":"2023/12/17/2023/云原生/基于K8S私有化交付要注意几点问题/","text":"公众号「架构成长指南」，专注于生产实践、云原生、分布式系统、大数据技术分享 在使用 k8s 进行项目私有化部署时，会遇到很多问题，以下把作者经常遇到的一些问题以及需要注意的点分享给各位。 资源依赖问题在进行私有化部署时，我们的系统会依赖很多外部资源与服务，比如： 服务器资源 外部服务 网络资源 服务器资源申请需要提前根据客户提供的业务数据，以及结合自身系统微服务数量等维度，梳理出一个服务器资源配置清单，提前申请资源。 示例 名称 类型 操作系统版本 CPU 磁盘 内存 数量 中间件服务器 ECS CentOS 7.9 8 500 16 5 应用服务器 ECS 16 500 32 20 K8S Master 云服务 1 NAS 云服务 外部服务结合业务需求，梳理依赖的外部服务清单，比如短信服务、地图Api、公众号、小程序等，需提前申请，以免影响项目交付。 网络相关资源 SSL证书，如果系统开放到外网必须要有 SSL证书，建议申请通配符证书，这种没有域名数量限制问题，如下图，只要属于 feishu.cn 下的二级域名，都可以用此证书。 公网443&#x2F;80 端口备案，部分应用强制依赖这些端口，比如小程序，需要提前进行备案，而且周期较长。 负载均衡器选择在未使用k8s时，常用Nginx进行SLB和前端资源部署，类似如下图而使用k8s以后，Nginx功能被削弱了很多，比如转发规则，可以放在Ingress 进行配置，前端资源也部署k8s 中 而Nginx只充当 SLB的作用，例如把前端请求转发到Ingress 中，功能很单一，而不管是公有云或私有云，厂商都提供了SLB，因此就不需要Nginx这一层，由厂商提供的SLB 直接转发请求至Ingress 即可。 SSL证书挂载有了厂商提供的SLB，那么 SSL证书也没必要挂载在k8s 的 Ingress上，直接挂载SLB即可，如下图，经过负载均衡器的请求都进行了证书剥离，转换成了 http 系统开放策略整理根据业务需求，提前整理系统网络开放策略清单，交由相关人员进行配置，比如系统 A 内网访问，系统 B外网访问，如下图 名称 域名 是否对外 协议 外网映射端口 DNS 解析 IP SLBIP 目标 IP 系统 A a.feishu.com 是 https 443 公网 IP 172.18.xx.xx xxx 系统 b b.feishu.com 否 http 无 SLB IP 172.18.xx.xx xxx 产品分支与镜像管理分支管理 由于私有化部署，有些需求是个性化的，这部分需求与通用版本分支是无法兼容的，那么需要从代码分支上进行区分，比如项目有对应项目的分支，通用分支有通用分支，如果一个需求的功能是通用需求，建议在通用分支上改造，测试完在合并至项目分支，其实不管用那种方式，要保证兼容性，可追溯。 分支类型 规则 示例 说明 项目开发分支 作者-项目简称-需求名称 zs-xs-需求名称 项目测试分支 项目名称-demo 项目名称-demo 项目测试生产分支 项目名称-master xs-master 项目代码发布打tag，版本包括三类：大版本(x.0.0) 、小版本(x.x.0) 、补丁(x.x.x) 镜像TAG管理 镜像的tag要与代码 tag相互联系起来，比如代码 tag 是：realse-1.0.0，那么镜像 tag也建议是这个名称，这样如果出问题，可以根据镜像 tag快速找到对应代码。","tags":[{"name":"架构成长指南","slug":"架构成长指南","permalink":"https://dongweizhao.github.io/tags/%E6%9E%B6%E6%9E%84%E6%88%90%E9%95%BF%E6%8C%87%E5%8D%97/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://dongweizhao.github.io/tags/Kubernetes/"},{"name":"私有化部署","slug":"私有化部署","permalink":"https://dongweizhao.github.io/tags/%E7%A7%81%E6%9C%89%E5%8C%96%E9%83%A8%E7%BD%B2/"},{"name":"私有化交付","slug":"私有化交付","permalink":"https://dongweizhao.github.io/tags/%E7%A7%81%E6%9C%89%E5%8C%96%E4%BA%A4%E4%BB%98/"}]},{"title":"从物理机到K8S：应用系统部署方式的演进及其影响","date":"2023-12-17T05:12:21.271Z","path":"2023/12/17/2023/云原生/从物理机到K8S：应用系统部署方式的演进及其影响/","text":"公众号「架构成长指南」，专注于生产实践、云原生、分布式系统、大数据技术分享。 概述 随着科技的进步，软件系统的部署架构也在不断演进，从以前传统的物理机到虚拟机、Docker和Kubernetes，我们经历了一系列变化。 这些技术的引入给我们带来了更高的资源利用率、更快的部署速度和更强大的扩展性，下面让我们一起探索这些演进，了解如何从传统部署走向现代化架构，为软件系统的开发和部署带来更多的便利和灵活性。 物理机部署 物理机部署在计算机早期阶段比较盛行，因为那时候虚拟化和云计算等技术还没有普及，物理机是主要的部署选择。 优点 性能和资源控制：物理机提供了直接访问硬件资源的能力，在某些对性能要求较高的应用场景中，可以实现更好的性能表现。 硬件特定需求：某些应用程序可能对特定硬件设备或外部接口有依赖，例如需要直接访问物理网卡或存储设备 缺点系统资源利用率较低 不同应用程序依赖于同一类库的不同版本，必须使用不同的机器 不同的应用程序不能共用同一端口，这使得在某些场景下，即使计算节点还有足够的计算资源，依然无法通过 部署多个实例来提供服务 系统资源无法进行有效隔离 很可能出现一个应用程序耗光所有资源，导致其他应用程序无法正常运行的情况。 无法做到应用程序快速弹性扩容 运维方式 物理机代表：IBM小型机、HP小型机，在此架构和部署的模式下，哪种应用部署在哪些节点上，往往是固定不变的，这使得自动化运维变得困难重重，通常的做法是人工维护应用与服务器之间的关系表 虚拟机部署虚拟机是一种将物理计算机资源划分为多个独立的虚拟环境的技术，通过虚拟化软件，可以在一台物理服务器上运行多个虚拟机，云计算的兴起和发展，使得虚拟机得到了更广泛的应用，截止目前，大部分还是有在用虚拟机部署。 优点 硬件资源隔离 资源的充分利用 缺点 运维管理成本较高，需要管理的主机数量是原来的数倍，管理复杂度的提升显而易见 依赖库需要单独安装，版本很难保持一致 不容易迁移 运维方式 小公司自建私有云，采用业界开源OpenStack的云平台进行管理，大的公有云公司采用自己的云平台进行管理，如：阿里云、腾讯云、华为云、青云、AWS 容器化部署 容器化部署主要是以Docker为代表，Docker的出现填补了传统虚拟化技术的一些不足之处，如启动时间长、资源占用高等问题。它通过利用Linux内核的容器特性，实现了更为轻量级的虚拟化解决方案，所以不少公司采用了这种方式部署。 优点一致的运行环境 提供了除内核外完整的运行时环境，确保了应用运行环境一致性 快速移植 由于 Docker 确保了执行环境的一致性，使得应用的迁移更加容易。Docker 可以在很多平台上运行，无论是物理机、虚拟机、公有云、私有云，甚至是笔记本，其运行结果是一致的 更快速的启动时间 传统的虚拟机技术启动应用服务往往需要数分钟，而 Docker 容器应用，由于直接运行于宿主内核，无需启动完整的操作系统，因此可以做到秒级、甚至毫秒级的启动时间。大大的节约了开发、测试、部署的时间 更高效的利用系统资源 由于容器不需要进行硬件虚拟以及运行完整操作系统等额外开销，Docker 对系统资源的利用率更高。无论是应用执行速度、内存损耗或者文件存储速度，都要比传统虚拟机技术更高效 缺点 由于容器数量庞大，通过手动运维方式工作量比较大 与虚拟机比较 特性 容器 虚拟机 启动 秒级 分钟级 硬盘使用 MB GB 性能 接近原生 弱于 系统支持量 单机支持上千个容器 一般几十个 管理成熟度 已k8s为代表 以OpenStack、vmware为代表 K8S部署 尽管Docker提供了一种方便的容器化解决方案，但在进行大规模部署和管理时，会面临大量的版本更新升级部署，以及高可用的管理等问题。 而Kubernetes提供了更强大和全面的容器管理和编排功能，他能够自动处理复杂的任务，如容器调度、扩缩容、服务发现和负载均衡等，简化了部署和管理过程，同时提供了更好的可扩展性和可靠性，所以是现在各大公司采用的主流部署方式。 优点应用自动化部署 只需要执行一个命令，就可以把服务启动起来，而不用关心该部署到那个节点上。 弹性扩缩容 使用一个简单的命令、控制台 或基于 CPU 内存使用情况自动对应用程序进行扩容或者缩容 灰度发布 保证在应用版本升级时，对线上用户无感知 多环境部署支持 支持公有云，私有云，混合云，多重云部署 可维护好 提供了专门的运维系统界面，可以在线管理大规模应用，进行升级、回滚、监控等，比如 Rancher、KubeSphere 缺点 K8s 系统架构比较复杂，对于初学者门槛有点高 运维方式采用k8s进行容器管理，在发布服务时，构建基础容器镜像，到镜像仓库，在对应环境访问镜像仓库，拉取对应容器镜像进行部署 以上我们介绍了物理机、虚拟机、容器化和K8s部署区别，我们可以根据自身的需求选择最适合自己的部署方式，希望对你有所帮助。","tags":[{"name":"架构成长指南","slug":"架构成长指南","permalink":"https://dongweizhao.github.io/tags/%E6%9E%B6%E6%9E%84%E6%88%90%E9%95%BF%E6%8C%87%E5%8D%97/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://dongweizhao.github.io/tags/Kubernetes/"},{"name":"系统部署架构演进","slug":"系统部署架构演进","permalink":"https://dongweizhao.github.io/tags/%E7%B3%BB%E7%BB%9F%E9%83%A8%E7%BD%B2%E6%9E%B6%E6%9E%84%E6%BC%94%E8%BF%9B/"},{"name":"从docker到k8s","slug":"从docker到k8s","permalink":"https://dongweizhao.github.io/tags/%E4%BB%8Edocker%E5%88%B0k8s/"}]},{"title":"什么是革命性技术eBPF？为什么可观测性领域都得用它","date":"2023-12-17T04:54:56.349Z","path":"2023/12/17/2023/云原生/什么是革命性技术eBPF？为什么可观测性领域都得用它/","text":"公众号「架构成长指南」，专注于生产实践、云原生、分布式系统、大数据技术分享。 如果有一种技术可以监控和采集任何应用信息，支持任何语言，并且应用完全无感知，零侵入，想想是不是很激动，那么这个技术是什么呢？就是eBPF，它应该是最近一两年非常热门的技术名词，我相信你或多或少都看到过，但可能不知道它能做什么，今天我们来讲讲这个革命性的技术eBPF，以及它在可观测领域的应用eBPF是什么？ eBPF 是什么？ eBPF（extended Berkeley Packet Filter）是在 Linux 内核中运行的虚拟机技术，2014 年它首次出现在 Linux 内核中，并经过这几年迭代，目前已经成熟。它提供了一种灵活并且安全的方式来扩展内核功能。eBPF 最初是为网络数据包过滤而设计的，但现在已经扩展到其它领域，如安全监控、性能分析和系统跟踪等。 eBPF允许用户在不修改内核源代码的情况下，通过加载和执行自定义的eBPF程序来扩展内核功能。这些eBPF程序通过Hook 机制与内核交互，它们可以对进入和离开内核的事件进行过滤和处理，以实现网络数据包的监控、性能统计和安全审计等功能。 如下图，eBPF可以在文件写入和读取进行拦截处理，网络的发送和接受进行拦截处理 这段代码是一个 eBPF 过滤器程序，用于在网络数据包通过时打印源 IP 地址和目标 IP 地址。它使用 bpf_printk 函数来输出信息到内核日志。 1234567891011121314151617181920212223242526#include &lt;linux/bpf.h&gt;#include &lt;linux/if_ether.h&gt;#include &lt;linux/ip.h&gt;#include &lt;linux/in.h&gt;SEC(&quot;filter&quot;)int print_ip(struct __sk_buff *skb) &#123; struct ethhdr *eth = bpf_hdr_pointer(skb); struct iphdr *ip = (struct iphdr *)(eth + 1); if (eth-&gt;h_proto == htons(ETH_P_IP)) &#123; bpf_printk(&quot;Source IP: %u.%u.%u.%u\\n&quot;, ip-&gt;saddr &amp; 0xFF, (ip-&gt;saddr &gt;&gt; 8) &amp; 0xFF, (ip-&gt;saddr &gt;&gt; 16) &amp; 0xFF, (ip-&gt;saddr &gt;&gt; 24) &amp; 0xFF); bpf_printk(&quot;Destination IP: %u.%u.%u.%u\\n&quot;, ip-&gt;daddr &amp; 0xFF, (ip-&gt;daddr &gt;&gt; 8) &amp; 0xFF, (ip-&gt;daddr &gt;&gt; 16) &amp; 0xFF, (ip-&gt;daddr &gt;&gt; 24) &amp; 0xFF); &#125; return XDP_PASS;&#125; eBPF 能做什么？动态编程内核以实现高效的网络、可观测性、追踪和安全性。 1.可观测性eBPF 程序是事件驱动的，当内核或用户程序经过一个 eBPF Hook 时，对应 Hook 点上加载的 eBPF 程序就会被执行。从而可以采集相关信息，而且它是完全无侵入，对应用系统来说完全无感知。 想想以前我们用的监控系统Cat、SkyWalking或多或少都有侵入，只是代码多少的问题，有了它完全不用关心，而且它能对所有运行在 linux 上面应用进行监控，比如redis、kafka等 2.安全监控和审计eBPF可以用于实时监控系统的安全事件和异常行为。它可以检测恶意软件、网络攻击、未经授权的访问等安全威胁，并触发警报或采取相应的防御措施。 3.自定义功能扩展如数据包处理、协议解析、数据转换等。 eBPF 在可观测性方案的应用可观测性，也是近几年非常热门的话题，因为目前互联网公司应用大部分都基于 k8s 部署，而 k8s 的网络模型比较复杂，如果系统出现异常，无法快速定位问题，所以需要有一个的平台可以去做系统故障定位、性能优化、以及监控等工作，而可观测性提供了更深入的洞察力和更好的理解，使得在复杂的分布式系统中构建、部署和维护应用程序更加可靠和高效如何做好一个可观测性系统，那么eBPF技术是绕不开的，下面看下eBPF是如何抓取应用数据 eBPF 是如何抓取应用数据的可能有人会问eBPF是怎么抓取数据，因为进入系统内核都是二进制数据，如何知晓是kafka或者mongodb的数据，答案是基于通信协议，每个中间件都是属于自身的通信协议，比如 redis、mysql、mongodb等,以下为mongodb的原始通信报文，这个报文每几位代表什么含义，在mongodb官方文档都有定义引用于:郑志聪老师在 2023 云原生+可观测性广州 Meeup 分享 mongodb 消息解析由于作者本人的电脑为MAC M系列芯片，对eBPF不怎么兼容，所以我们下面只讲原理，如下图是mongodb通信协议，基于这个协议，可以知晓消息内容、操作类型、响应码等。 1234567struct MsgHeader &#123; int32 messageLength; // total message size, including this int32 requestID; // identifier for this message int32 responseTo; // requestID from the original request // (used in responses from the database) int32 opCode; // message type&#125; https://www.mongodb.com/docs/manual/reference/mongodb-wire-protocol/ 基于这个消息协议，eBPF就可以完成数据解析和抽取 基于 eBPF 构建的可观测性平台目前很多公司都基于 eBPF技术在构建自己的可观测性平台，下面介绍一些相关产品 阿里云应用监控 eBPF 版它是一套针对 Kubernetes 集群开发的一站式可观测性产品，它能做到： 代码无侵入：阿里云应用监控 eBPF 版通过旁路技术，不需要对代码进行埋点即可获取到丰富的网络性能数据。 语言无关：阿里云应用监控 eBPF 版在内核层进行网络协议解析，支持任意语言，任意框架。 高性能：阿里云应用监控 eBPF 版基于 eBPF 技术，能以极低的消耗获取丰富的网络性能数据。 资源关联：阿里云应用监控 eBPF 版通过网络拓扑，资源拓扑展示相关资源的关联。 数据多样：阿里云应用监控 eBPF 版支持可观测的各种类型数据（监控指标、链路、日志和事件）。 整体性：阿里云应用监控 eBPF 版通过控制台的场景设计，关联起架构感知拓扑、Prometheus 监控、告警配置。 部分效果图 dashboard 拓扑图 https://help.aliyun.com/zh/arms/application-monitoring-ebpf/product-overview/what-is-alibaba-cloud-application-monitoring-ebpf-version 开源监控系统 deepFlowDeepFlow 开源项目旨在为复杂的云基础设施及云原生应用提供深度可观测性。DeepFlow 基于 eBPF 实现了零侵扰（Zero Code）的指标、分布式追踪、调用日志、函数剖析数据采集，并结合智能标签（SmartEncoding）技术实现了所有观测数据的全栈（Full Stack）关联和高效存取，核心特性如下： 任意 Service 的全景图：利用 eBPF 零侵扰绘制生产环境的全景图。 任意 Request 的分布式追踪：基于 eBPF 的零侵扰分布式追踪能力，支持任意语言的应用程序，并完整覆盖网关、服务网格、数据库、消息队列、DNS、网卡等各类基础设施。 任意 Function 的持续性能剖析：以低于 1% 的开销零侵扰采集生产环境进程的性能剖析数据。 无缝集成流行的可观测性技术栈：可作为 Prometheus、OpenTelemetry、SkyWalking、Pyroscope 的存储后端。 存储性能 10x ClickHouse：基于 SmartEncoding 机制，向所有观测信号注入标准化的、预编码的元标签，相比 ClickHouse 的 String 或 LowCard 方案均可将存储开销降低 10x。 部分效果图 redis 监控 请求日志 分布式链路追踪 sql 监控 https://github.com/deepflowio/deepflow/blob/main/README-CN.md SkyWalking众多周知SkyWalking基于agent方式采集可观测性数据，比如java用java agent相关api编写，其它语言则编写对应语言的agent，这种方式可行，但是对技术人员要求较高。如果使用eBPF就不存在这种问题，目前看到SkyWalking也有往eBPF方向发展 部分效果图 引用于吴晟老师 SkyWalking2023 峰会演讲 PPT CiliumCilium 是一个开源项目，为 Kubernetes 集群和其它容器编排平台等云原生环境提供网络、安全和可观测性，它主要使用的技术就是eBPF https://cilium.io/ 总结以上我们介绍了eBPF是什么，以及它有哪些优势，同时讲解了它在可观测性领域的一些应用，希望对你有所帮助。","tags":[{"name":"eBPF","slug":"eBPF","permalink":"https://dongweizhao.github.io/tags/eBPF/"},{"name":"什么是eBPF","slug":"什么是eBPF","permalink":"https://dongweizhao.github.io/tags/%E4%BB%80%E4%B9%88%E6%98%AFeBPF/"},{"name":"可观测领域底层技术","slug":"可观测领域底层技术","permalink":"https://dongweizhao.github.io/tags/%E5%8F%AF%E8%A7%82%E6%B5%8B%E9%A2%86%E5%9F%9F%E5%BA%95%E5%B1%82%E6%8A%80%E6%9C%AF/"}]},{"title":"如何基于 k8s做私有化部署","date":"2023-12-17T04:49:36.296Z","path":"2023/12/17/2023/云原生/如何基于 k8s做私有化部署/","text":"公众号「架构成长指南」，专注于生产实践、云原生、分布式系统、大数据技术分享。 随着国内数字化转型的加速和国产化进程推动，软件系统的私有化部署已经成为非常热门的话题，因为私有化部署赋予了企业更大的灵活和控制权，使其可以根据自身需求和安全要求定制和管理软件系统。下面分享下我们的基于k8S私有化部署经验。 私有化交付的目标 要支持系统快速部署至客户机房 支持版本在线升级 支持动态扩容 能快速集成系统监控告警 支持在线运维 可快速移植 以上目标，目前最合适的就是k8s，原因如下 如果基于jar部署，系统快速部署和动态扩容就无法满足，pass。 docker-compose在快速部署、快速迁移可以满足，但是其他方面是满足不了，比如动态扩容，以及图形化的在线运维等。 因此基于k8s做私有化交付是最合适的方案，当然如果项目规模比较小，就几个服务也没有动态扩容等需求，那么也没必要引入k8s，如果项目规模较大，使用k8s进行私有化部署是不错的解决方案。 基于k8s私有化部署如何做？以上我们确认了使用k8s做私有化部署，但是还有一些细节问题，需要考虑 在公司内部一般使用gitlab+Jenkins做服务部署，在客户现场，这种方式一般不可行，因为一般不允许在客户现场访问公司的代码仓库 镜像仓库要能支持公网访问，这样才可以在客户机房下载到镜像 一个服务就有很多yaml文件，如果几十个服务的yaml文件怎么管理，如何快速部署或者升级 中间件要支持快速部署，有些中间件不能部署在k8s，所以需要支持自动化脚本快速部署。 系统配置如何管理，每个服务都依赖数据库、消息等中间件，这些地址怎么管理起来 基于问题，我们的解决方案如下： 在公司内部构建镜像时，直接推送至公网镜像仓库Harbar，在客户机房直接拉取部署，而部署服务使用Helm进行部署，Helm是一个 k8s的包管理工具，他可以把一组服务yaml文件管理起来，并且支持部署和更新，非常方便。比如有一个文件系统，包括Deployment、Service、gateway vs、pv pvc等文件，如果用Helm管理起来,如下图上面文件，可以认为是模板，其中有一个配置文件，values.yaml，所有的可变都在这里面维护，在 要部署这个文件系统，执行以下命令即可完成。 12345678910111213helm install fss myrepo/fss \\--set pv.log.type=storageClass \\--set pv.log.pvc.storageName=gfs-storage \\--set pv.log.pvc.storage=5Gi \\--set pv.file.type=storageClass \\--set pv.file.pvc.storageName=gfs-storage \\--set pv.file.pvc.storage=1Gi \\--set istioGateway.schema=http \\--set istioGateway.hosts=&#123;test-user.com&#125; \\--set istioGateway.ucenterHost=test-order.com \\--set apollo.cluster=test\\--set sv.fssManager.replicaCount=1 \\--set sv.fssRest.replicaCount=1 中间件部署，对部署在k8s外部的中间件，可以使用Ansiable编写自动化脚本，进行快速部署，几分钟就可以部署一个高可用集群。 系统参数配置，一般使用Nacos或Apollo 进行管理配置，但是由于服务过多，配置起来工作量相对较大，而且很多都是重复工作。比如数据库地址、kafka地址、es地址都是相同的，那么如何避免做重复工作，比如可以写一个shell脚本把公共的参数提取出来，然后进行修改替换，或者写一个运维部署平台，把相关公共参数进行图形化配置，并对接配置中心，进行发布替换。 系统监控告警，目前可使用deepFlow、kube-prometheus、夜莺等解决方案 在线运维平台，可以使用Rancher或KuberSphere，这两个都是目前非常热门图形化运维平台 快速移植，k8s设计之初就考虑到移植性的问题，所以与底层基础设施无关联性，所以不管是在公有云、私有云、混合云都是可以进行部署的，而且现在各大云厂商，都有 k8s 的商用解决方案，让我们部署起来更加快速，也不用考虑集群的稳定性，比如阿里的ACK、华为的CCE、腾讯云的TKE等。 总结以上我们介绍私有化部署的难点，并引申出了私有化部署整体解决方案，后续还会更新更多私有化部署相关文章，比如存储怎么挂载、域名怎么管理、监控告警怎么配置等，请持续关注。","tags":[{"name":"架构成长指南","slug":"架构成长指南","permalink":"https://dongweizhao.github.io/tags/%E6%9E%B6%E6%9E%84%E6%88%90%E9%95%BF%E6%8C%87%E5%8D%97/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://dongweizhao.github.io/tags/Kubernetes/"},{"name":"k8s","slug":"k8s","permalink":"https://dongweizhao.github.io/tags/k8s/"},{"name":"私有化部署","slug":"私有化部署","permalink":"https://dongweizhao.github.io/tags/%E7%A7%81%E6%9C%89%E5%8C%96%E9%83%A8%E7%BD%B2/"},{"name":"如何基于 k8s做私有化部署","slug":"如何基于-k8s做私有化部署","permalink":"https://dongweizhao.github.io/tags/%E5%A6%82%E4%BD%95%E5%9F%BA%E4%BA%8E-k8s%E5%81%9A%E7%A7%81%E6%9C%89%E5%8C%96%E9%83%A8%E7%BD%B2/"}]},{"title":"10个常见的 Kubernetes 陷阱和挑战","date":"2023-12-17T04:40:55.190Z","path":"2023/12/17/2023/云原生/10个常见的 Kubernetes 陷阱和挑战/","text":"公众号「架构成长指南」，专注于生产实践、云原生、分布式系统、大数据技术分享 Kubernetes 是最流行的容器编排和部署平台。它的强大功能特性，可以保障在生产中可靠地运行容器化应用程序。 然而，有灵活性的同时也带来了复杂性，在本文中，我们将探讨许多团队遇到的 10个常见 Kubernetes 陷阱。能够识别并避免这些挑战将提高应用程序的可扩展性、可靠性和安全性，同时让你更好地控制集群及其部署。 1.使用 latest Tag 部署容器可以说，Kubernetes 最常被违反的最佳实践之一就是在部署容器时使用latest标签。这将使我们面临无意中接收重大变更的风险，而这些变更可能影响系统稳定性。 每个人使用 latest 标签的方式各不相同，但大多数人都会将 latest 指向其项目的最新版本。例如，今天使用 helm:latest 将提供 Helm v3，但在v4版本发布后，重启就会更新到v4，但是我们可能还认为系统运行的是 v3 版本，从而引发不可预知的风险。 2.不使用Liveness和Readiness 探针探针可以使我们的应用程序更具弹性。它们会告知 Kubernetes Pod 的健康状况。 当容器出现问题时，比如内存溢出，Liveness探针请求超时，那么Liveness探针会通知 Kubernetes 重启容器。 有时候应用会暂时性地无法为请求提供服务。 例如，应用在启动时可能需要加载大量的数据或配置文件，或是启动后要依赖等待外部服务。 在这种情况下，既不想杀死应用，也不想给它发送请求。 Kubernetes 提供了Readiness探针来发现并缓解这些情况，容器所在 Pod 上报还未就绪的信息，并且不接受通过 Kubernetes Service 的流量。 下面是一个包含有效性和就绪性探针的简单 Pod： 12345678910111213141516apiVersion: v1kind: Podmetadata: name: probes-demospec: containers: - name: probes-demo image: nginx:latest livenessProbe: httpGet: path: / port: 80 readinessProbe: httpGet: path: / port: 80 3. 缺少节点选择器导致调度效率低下集群的整体性能取决于 Pod 是否被正确调度到合适的节点上。许多集群包含多种类型的节点，例如用于标准应用程序的小型 2 CPU/4 GB节点和用于密集后端服务的较大8 CPU/16GB节点。 如果Pod无法可靠地调度到我们想要的节点池，那么集群利用率将会很低。例如即使有未充分利用的较小节点，也会强制创建不必要的新的较大节点，从而增加集群的成本。通过在节点上设置标签，然后使用节点选择器将每个 Pod 分配给兼容的节点来避免此问题： 12345678910apiVersion: v1kind: Podmetadata: name: pod-node-selector-demospec: containers: - name: nginx image: nginx:latest nodeSelector: node-class: 2vcpu4gb 此 Pod 只会调度到设置了标签的节点node-class: 2vcpu4gb 使用命令在匹配的节点上设置标签：kubectl label 设置适当的调度规则将最大限度地提高节点利用率并保持稳定的集群性能。 4.破坏 Pod 亲和性&#x2F;反亲和性规则Pod 亲和性和反亲和性规则允许指示 Kubernetes 哪个节点最适合部署Pod。规则可以以节点级特征（例如标签）或已在节点上运行的其他 Pod 的特征为条件。 亲和性规则将Pod吸引到 Node，使得 Pod 更有可能调度到特定Node上，而反亲和性则具有排斥作用，降低了调度的概率。 Kubernetes 会评估每个可用于调度的可能节点的 Pod 亲和性规则，然后选择最合适的一个。 亲和力系统能够支持复杂的调度行为，但也很容易错误配置亲和力规则，Pod会意外地调度到不正确的节点，或者拒绝调度。 比如一个服务的两个副本，应该调度在两个Node上，这样如果一个 Node 节点发生故障时，可以保证服务的另一个副本可用，如果规则设置不正确都调度到一个Node 上那么会导致服务不可用。 5. 没有监控&#x2F;记录当在Kubernetes 中扩容应用程序时，了解集群资源利用率、应用程序错误和实时性能数据至关重要。内存消耗激增、Pod 驱逐和容器崩溃都是我们应该了解的问题，但标准 Kubernetes不具备任何可观测性功能，以便在故障发生时发出告警。 要启用对集群的监控，我们应该部署可观测性平台，例如 Prometheus、夜莺。这会从 Kubernetes 收集指标，同时在Grafana查看相关数据指标。同时也有告警机制。 6. 标签选择器不匹配 部署和服务等对象依赖正确的标签选择器来识别 Pod 及其管理的其他对象。选择器与实际分配给对象的标签之间的不匹配将导致部署失败。 示例 123456789101112131415161718apiVersion: apps/v1kind: Deploymentmetadata: name: demo-deploymentspec: replicas: 2 selector: matchLabels: app: nginx-demo-app template: metadata: labels: # Label does not match the deployment&#x27;s selector! app: nginx-demo-application spec: containers: name: nginx-demo-app image: nginx:latest 以上文件部署会抛出selector does not match template labelsspec.selector.matchLabelsspec.template.metadata.labels要解决此问题，请调整清单的 和 字段，使它们具有相同的键值对 7. 服务端口不匹配同样，确保Service将流量路由到Pod上的正确端口也很重要。不正确的端口定义可能会使 Pod 看起来像是发生了故障，而实际上流量根本没有到达该 Pod。 以下清单包含此问题的示例。该Service监听9000端口并将流量转发到其 Pod上的8080端口 ，但容器实际上端口是80，所以流量无法到达。 12345678910111213141516171819202122232425apiVersion: v1kind: Podmetadata: name: demo-pod labels: app: demo-appspec: image: nginx:latest ports: - containerPort: 80---apiVersion: v1kind: Servicemetadata: name: demo-servicespec: ports: - port: 9000 protocol: TCP targetPort: 8080 selector: app: demo-app 8. 意外部署到错误的命名空间Kubernetes命名空间将一组服务逻辑分组在一起，在集群中提供一定程度的隔离。为每个团队、应用和环境创建命名空间可以防止名称冲突并简化管理体验。 使用命名空间时，请记住为每个服务和Kubectl命令指定目标命名空间。否则，将使用默认命名空间default。如果服务没有部署在合适的命名空间下，会导致相关服务器请求不可达。 以下清单为Istio Ingress转发配置，此文件部署在seg空间下，然后根据/dp-manager请求，转发到seg空间下的dp-manager-backend服务，如果dp-manager-backend不在seg空间下，那么会导致请求异常。 1234567891011121314151617181920apiVersion: networking.istio.io/v1beta1kind: VirtualServicemetadata: name: dp-manager-vs namespace: segspec: gateways: - dp-manager-gateway hosts: - control-dpmanager.test.com http: - match: - uri: prefix: /dp-manager route: - destination: host: dp-manager-backend port: number: 80 9. 没有资源请求和限制的 Pod正确的资源管理对于保持集群的稳定性至关重要。Pod默认没有任何资源限制，除非我们对其进行配置，因此这可能会导致Node节点CPU 和内存耗尽。 在所有 Pod 上设置适当的资源请求和限制以减少资源争用。请求Kubernetes为我们的 Pod 预留特定数量的资源，防止其调度到无法提供足够容量的节点上。Limits设置Pod可以使用的最大资源量；超过 CPU 限制的 Pod 将受到限制，而达到内存限制则会提示内存不足 (OOM) 从而终止 Pod 允许。 请求和限制在 Pod 清单的 字段中定义：spec.container.resources, 1234567891011121314apiVersion: v1kind: Podmetadata: name: demo-podspec: containers: - name: demo-container image: nginx:latest resources: requests: cpu: 100m memory: 1Gi limits: memory: 2Gi 以上Pod 请求100m（1000m等于1核）CPU 时间和 1Gi 内存。它只会调度到可以提供足够资源的节点上。 Pod 还设置了内存限制，最大可以申请2Gi 内存。 最佳实践是将 Pod 的内存限制设置为等于其请求。通常不需要 CPU 限制，因为 Kubernetes 会按比例限制超出其请求的 Pod。 10. 集群自动扩容错误选择Kubernetes原因之一就是它的弹性扩容。正确配置可以使Kubernetes在需求高峰时自动添加新的 Pod 和节点，从而动态的水平和垂直扩容。但是不幸的是，很多团队它们的自动扩容是不可预测的。 因此定期检查集群的利用率，以检查它是否仍然适合您的工作负载。使用负载测试工具（例如Locust）测试自动扩缩规则，将多余的流量引导至集群。这可以使我们更早地发现问题，确保Pod 在实际流量到达时能够无缝扩容。","tags":[{"name":"架构成长指南","slug":"架构成长指南","permalink":"https://dongweizhao.github.io/tags/%E6%9E%B6%E6%9E%84%E6%88%90%E9%95%BF%E6%8C%87%E5%8D%97/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://dongweizhao.github.io/tags/Kubernetes/"},{"name":"k8s","slug":"k8s","permalink":"https://dongweizhao.github.io/tags/k8s/"},{"name":"k8s10 个常见挑战和陷阱","slug":"k8s10-个常见挑战和陷阱","permalink":"https://dongweizhao.github.io/tags/k8s10-%E4%B8%AA%E5%B8%B8%E8%A7%81%E6%8C%91%E6%88%98%E5%92%8C%E9%99%B7%E9%98%B1/"}]},{"title":"免费稳定几乎无门槛，我的ChartGPT助手免费分享给你","date":"2023-11-23T15:36:24.247Z","path":"2023/11/23/2023/工具/poe分享/","text":"公众号「架构成长指南」，专注于生产实践、云原生、分布式系统、大数据技术分享。 概述ChatGPT想必大家应该都不陌生了，大部分人或多或少都接触了，好多应该都是通过openAi的官方进行使用的，这个门槛对大部分人有点高，今天给大家分享一个作者目前已经在用的AI助手，注意他是免费的 他支持GPT多个版本，同时使用他的门槛很低，不需要国外的手机号，能上外网即可，同时它支持多个终端：MAC、Windows、Android、IOS。 功能介绍这个软件是一个集成商，集成了非常多的AI工具，大部分都是免费的，比如作者最常用的就是ChatGPT 我在工作中是怎么用他的一些底层细节问题可以问他 编程方面 其他方面 其他软件功能下面给大家看下其他软件的功能效果 怎么领取关注作者公众号，回复gpt领取，会发送相关地址，同时有不了解的，可以进群了解","tags":[{"name":"架构成长指南","slug":"架构成长指南","permalink":"https://dongweizhao.github.io/tags/%E6%9E%B6%E6%9E%84%E6%88%90%E9%95%BF%E6%8C%87%E5%8D%97/"},{"name":"chatGPT","slug":"chatGPT","permalink":"https://dongweizhao.github.io/tags/chatGPT/"},{"name":"AI","slug":"AI","permalink":"https://dongweizhao.github.io/tags/AI/"},{"name":"AIGC","slug":"AIGC","permalink":"https://dongweizhao.github.io/tags/AIGC/"}]},{"title":"Java Stream中的API你都用过了吗？","date":"2023-11-21T01:22:41.327Z","path":"2023/11/21/2023/java/JavaStream/","text":"公众号「架构成长指南」，专注于生产实践、云原生、分布式系统、大数据技术分享。 在本教程中，您将通过大量示例来学习 Java 8 Stream API。 Java 在 Java 8 中提供了一个新的附加包，称为 java.util.stream。该包由类、接口和枚举组成，允许对元素进行函数式操作。 您可以通过在程序中导入 java.util.stream包来使用流。 Stream提供以下功能：Stream不存储元素。它只是通过计算操作的管道传送来自数据结构、数组或 I&#x2F;O 通道等源的元素。 Stream本质上是函数式的，对流执行的操作不会修改其源。例如，过滤从集合获取的 Stream 会生成一个没有过滤元素的新 Stream，而不是从源集合中删除元素。 Stream是惰性的，仅在需要时才计算代码，在流的生命周期中，流的元素仅被访问一次。 与迭代器一样，必须生成新流才能重新访问源中的相同元素。您可以使用 Stream 来 过滤、收集、打印以及 从一种数据结构转换为其他数据结构等。 Stream API 示例1. 创建一个空的Stream在创建空流时，应使用 empty() 方法： 12Stream&lt;String&gt; stream = Stream.empty();stream.forEach(System.out::println); 通常情况下，在创建时会使用 empty() 方法，以避免在没有元素的流中返回 null： 123public Stream&lt;String&gt; streamOf(List&lt;String&gt; list) &#123; return list == null || list.isEmpty() ? Stream.empty() : list.stream();&#125; 2.从集合中创建流123456789101112131415161718192021222324import java.io.IOException;import java.util.Arrays;import java.util.Collection;import java.util.HashSet;import java.util.List;import java.util.Set;import java.util.stream.Stream;public class StreamCreationExamples &#123; public static void main(String[] args) throws IOException &#123; Collection&lt;String&gt; collection = Arrays.asList(&quot;JAVA&quot;, &quot;J2EE&quot;, &quot;Spring&quot;, &quot;Hibernate&quot;); Stream&lt;String&gt; stream2 = collection.stream(); stream2.forEach(System.out::println); List&lt;String&gt; list = Arrays.asList(&quot;JAVA&quot;, &quot;J2EE&quot;, &quot;Spring&quot;, &quot;Hibernate&quot;); Stream&lt;String&gt; stream3 = list.stream(); stream3.forEach(System.out::println); Set&lt;String&gt; set = new HashSet&lt;&gt;(list); Stream&lt;String&gt; stream4 = set.stream(); stream4.forEach(System.out::println); &#125;&#125; 输出 123456789101112JAVAJ2EESpringHibernateJAVAJ2EESpringHibernateJAVAHibernateJ2EESpring 3. 从数组中创建流对象数组可以是流的源，也可以从现有数组或数组的一部分创建数组： 12345678910111213141516171819202122232425262728import java.util.Arrays;import java.util.stream.Stream;public class StreamCreationExample &#123; public static void main(String[] args) &#123; // 使用Arrays.stream()创建流 int[] numbers = &#123;1, 2, 3, 4, 5&#125;; Stream&lt;Integer&gt; stream1 = Arrays.stream(numbers); System.out.println(&quot;Using Arrays.stream():&quot;); stream1.forEach(System.out::println); // 使用Stream.of()创建流 String[] names = &#123;&quot;Alice&quot;, &quot;Bob&quot;, &quot;Charlie&quot;&#125;; Stream&lt;String&gt; stream2 = Stream.of(names); System.out.println(&quot;Using Stream.of():&quot;); stream2.forEach(System.out::println); // 使用Stream.builder()创建流 String[] colors = &#123;&quot;Red&quot;, &quot;Green&quot;, &quot;Blue&quot;&#125;; Stream.Builder&lt;String&gt; builder = Stream.builder(); for (String color : colors) &#123; builder.add(color); &#125; Stream&lt;String&gt; stream3 = builder.build(); System.out.println(&quot;Using Stream.builder():&quot;); stream3.forEach(System.out::println); &#125;&#125; 输出 1234567891011121314Using Arrays.stream():12345Using Stream.of():AliceBobCharlieUsing Stream.builder():RedGreenBlue 4. 使用Stream过滤一个集合示例在下面的示例中，我们不使用流过滤数据，看看代码是什么样的，同时我们在给出一个使用stream过滤的示例，对比一下 不使用Stream过滤一个集合示例 12345678910111213141516171819202122232425import java.util.ArrayList;import java.util.List;public class FilterWithoutStreamExample &#123; public static void main(String[] args) &#123; List&lt;Integer&gt; numbers = new ArrayList&lt;&gt;(); numbers.add(10); numbers.add(20); numbers.add(30); numbers.add(40); numbers.add(50); List&lt;Integer&gt; filteredNumbers = new ArrayList&lt;&gt;(); for (Integer number : numbers) &#123; if (number &gt; 30) &#123; filteredNumbers.add(number); &#125; &#125; System.out.println(&quot;Filtered numbers (without Stream):&quot;); for (Integer number : filteredNumbers) &#123; System.out.println(number); &#125; &#125;&#125; 输出： 123Filtered numbers (without Stream):4050 使用 Stream 过滤集合示例： 1234567891011121314151617181920import java.util.ArrayList;import java.util.List;public class FilterWithStreamExample &#123; public static void main(String[] args) &#123; List&lt;Integer&gt; numbers = new ArrayList&lt;&gt;(); numbers.add(10); numbers.add(20); numbers.add(30); numbers.add(40); numbers.add(50); List&lt;Integer&gt; filteredNumbers = numbers.stream() .filter(number -&gt; number &gt; 30) .toList(); System.out.println(&quot;Filtered numbers (with Stream):&quot;); filteredNumbers.forEach(System.out::println); &#125;&#125; 输出： 123Filtered numbers (with Stream):4050 前后我们对比一下，可以看到，使用 Stream 进行集合过滤可以更加简洁和直观，减少了手动迭代和添加元素的步骤。它提供了一种声明式的编程风格，使代码更易读、可维护和可扩展。 5. 使用Stream过滤和遍历集合在下面的示例中，我们使用 filter() 方法进行过滤，使用 forEach() 方法对数据流进行迭代： 123456789101112131415161718import java.util.ArrayList;import java.util.List;public class FilterAndIterateWithStreamExample &#123; public static void main(String[] args) &#123; List&lt;String&gt; names = new ArrayList&lt;&gt;(); names.add(&quot;Alice&quot;); names.add(&quot;Bob&quot;); names.add(&quot;Charlie&quot;); names.add(&quot;David&quot;); names.add(&quot;Eve&quot;); System.out.println(&quot;Filtered names starting with &#x27;A&#x27;:&quot;); names.stream() .filter(name -&gt; name.startsWith(&quot;A&quot;)) .forEach(System.out::println); &#125;&#125; 输出 12Filtered names starting with &#x27;A&#x27;:Alice 在上述示例中，我们有一个字符串列表 names，其中包含了一些名字。我们使用 Stream 进行过滤和迭代操作以查找以字母 “A” 开头的名字。 6.使用Collectors方法求和我们还可以使用Collectors计算数值之和。 在下面的示例中，我们使用Collectors类及其指定方法计算所有产品价格的总和。 12345678910111213141516171819import java.util.ArrayList;import java.util.List;import java.util.stream.Collectors;public class SumByUsingCollectorsMethods &#123; public static void main(String[] args) &#123; List &lt; Product &gt; productsList = new ArrayList &lt; Product &gt; (); productsList.add(new Product(1, &quot;HP Laptop&quot;, 25000f)); productsList.add(new Product(2, &quot;Dell Laptop&quot;, 30000f)); productsList.add(new Product(3, &quot;Lenevo Laptop&quot;, 28000f)); productsList.add(new Product(4, &quot;Sony Laptop&quot;, 28000f)); productsList.add(new Product(5, &quot;Apple Laptop&quot;, 90000f)); double totalPrice3 = productsList.stream() .collect(Collectors.summingDouble(product -&gt; product.getPrice())); System.out.println(totalPrice3); &#125;&#125; 输出 1201000.0 7. 使用Stream查找年龄最大和最小的学生假设有一个 Student 类具有 name 和 age 属性。我们可以使用 Stream 来查找学生集合中年龄的最大和最小值，并打印出相应的学生信息。以下是一个示例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455import java.util.ArrayList;import java.util.Comparator;import java.util.List;import java.util.Optional;public class StudentStreamExample &#123; public static void main(String[] args) &#123; List&lt;Student&gt; students = new ArrayList&lt;&gt;(); students.add(new Student(&quot;Alice&quot;, 20)); students.add(new Student(&quot;Bob&quot;, 22)); students.add(new Student(&quot;Charlie&quot;, 19)); students.add(new Student(&quot;David&quot;, 21)); // 查找年龄最大的学生 Optional&lt;Student&gt; maxAgeStudent = students.stream() .max(Comparator.comparingInt(Student::getAge)); // 查找年龄最小的学生 Optional&lt;Student&gt; minAgeStudent = students.stream() .min(Comparator.comparingInt(Student::getAge)); // 打印最大和最小年龄的学生信息 System.out.println(&quot;Student with maximum age:&quot;); maxAgeStudent.ifPresent(System.out::println); System.out.println(&quot;Student with minimum age:&quot;); minAgeStudent.ifPresent(System.out::println); &#125;&#125;class Student &#123; private String name; private int age; public Student(String name, int age) &#123; this.name = name; this.age = age; &#125; public String getName() &#123; return name; &#125; public int getAge() &#123; return age; &#125; @Override public String toString() &#123; return &quot;Student&#123;&quot; + &quot;name=&#x27;&quot; + name + &#x27;\\&#x27;&#x27; + &quot;, age=&quot; + age + &#x27;&#125;&#x27;; &#125;&#125; 输出： 1234Student with maximum age:Student&#123;name=&#x27;Bob&#x27;, age=22&#125;Student with minimum age:Student&#123;name=&#x27;Charlie&#x27;, age=19&#125; 8. 使用Stream转换List为Map12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import java.util.ArrayList;import java.util.List;import java.util.Map;import java.util.stream.Collectors;public class StudentStreamToMapExample &#123; public static void main(String[] args) &#123; List&lt;Student&gt; students = new ArrayList&lt;&gt;(); students.add(new Student(&quot;Alice&quot;, 20)); students.add(new Student(&quot;Bob&quot;, 22)); students.add(new Student(&quot;Charlie&quot;, 19)); students.add(new Student(&quot;David&quot;, 21)); // 将学生列表转换为 Map，以姓名为键，学生对象为值 Map&lt;String, Student&gt; studentMap = students.stream() .collect(Collectors.toMap(Student::getName, student -&gt; student)); // 打印学生 Map for (Map.Entry&lt;String, Student&gt; entry : studentMap.entrySet()) &#123; System.out.println(entry.getKey() + &quot;: &quot; + entry.getValue()); &#125; &#125;&#125;class Student &#123; private String name; private int age; public Student(String name, int age) &#123; this.name = name; this.age = age; &#125; public String getName() &#123; return name; &#125; public int getAge() &#123; return age; &#125; @Override public String toString() &#123; return &quot;Student&#123;&quot; + &quot;name=&#x27;&quot; + name + &#x27;\\&#x27;&#x27; + &quot;, age=&quot; + age + &#x27;&#125;&#x27;; &#125;&#125; 输出 1234David: Student&#123;name=&#x27;David&#x27;, age=21&#125;Bob: Student&#123;name=&#x27;Bob&#x27;, age=22&#125;Charlie: Student&#123;name=&#x27;Charlie&#x27;, age=19&#125;Alice: Student&#123;name=&#x27;Alice&#x27;, age=20&#125; 在上面示例中，我们使用Collectors.toMap() 方法将学生列表转换为 Map。我们指定了键提取器 Student::getName，将学生的姓名作为键。对于值提取器，我们使用了一个匿名函数 student -&gt; student，它返回学生对象本身作为值。 9. 使用Stream把List对象转换为另一个List对象假设我们有一个 Person 类，其中包含姓名和年龄属性。我们可以使用 Stream 来将一个 List 对象转换为另一个 List 对象，其中只包含人员的姓名。以下是一个示例： 12345678910111213141516171819202122232425262728293031323334353637383940 import java.util.ArrayList;import java.util.List;import java.util.stream.Collectors;public class ListTransformationExample &#123; public static void main(String[] args) &#123; List&lt;Person&gt; persons = new ArrayList&lt;&gt;(); persons.add(new Person(&quot;Alice&quot;, 20)); persons.add(new Person(&quot;Bob&quot;, 22)); persons.add(new Person(&quot;Charlie&quot;, 19)); // 将 Person 列表转换为只包含姓名的 String 列表 List&lt;String&gt; names = persons.stream() .map(Person::getName) .collect(Collectors.toList()); // 打印转换后的姓名列表 System.out.println(names); &#125;&#125;class Person &#123; private String name; private int age; public Person(String name, int age) &#123; this.name = name; this.age = age; &#125; public String getName() &#123; return name; &#125; public int getAge() &#123; return age; &#125;&#125;``` 输出： [Alice, Bob, Charlie] 在上述示例中，我们有一个 `Person` 类，其中包含姓名和年龄属性。我们创建了一个 persons 列表，并添加了几个 Person 对象。 使用`Stream`，我们通过调用 `map()` 方法并传入一个方法引用 Person::getName，最后，我们使用 `collect() `方法和 `Collectors.toList()` 将转换后的姓名收集到一个新的列表中。 ### API https://docs.oracle.com/javase/8/docs/api/java/util/stream/package-summary.html","tags":[{"name":"java","slug":"java","permalink":"https://dongweizhao.github.io/tags/java/"},{"name":"架构成长指南","slug":"架构成长指南","permalink":"https://dongweizhao.github.io/tags/%E6%9E%B6%E6%9E%84%E6%88%90%E9%95%BF%E6%8C%87%E5%8D%97/"},{"name":"Stream","slug":"Stream","permalink":"https://dongweizhao.github.io/tags/Stream/"},{"name":"后端","slug":"后端","permalink":"https://dongweizhao.github.io/tags/%E5%90%8E%E7%AB%AF/"}]},{"title":"04 分库分表的案例分享","date":"2020-06-29T03:26:34.000Z","path":"2020/06/29/2022/数据库中间件/案例分享/","text":"本节对在其它银行实施的案例，进行一个分享 业务分析本次分享的系统是一个客户信息系统，首先分析行内现有用户数据量大概为1千万，业务需求都是以用户的维度出发所以用户ID作为分片键比较合适,考虑后续数据迁移的问题，分片规则采用一致性hash。 基于以上原则，对数据库表进行设计，表分为两类：分别为参数类表、业务类表，所以先进行垂直切分，其中业务类是需要分片的，所以在进行水平切分。 预设分片 考虑未来5年的客户数据量增长到6千万—8千万，单表按1000万的数据量上限来考虑，需要预设8个分片，考虑到未来比较大的数据增量，预设32个分片； 考虑到前期上线后2-3年内大约2000万的数据量（包括近1000万的存量数据），系统上线初期配置2个物理节点，每个节点16个分片（SCHEMA），每个分片（SCHEMA）单表大约62.5万的数据记录数，其中默认节点放在其中一台物理节点中。 未来根据客户量的增长情况进行扩容处理，按预设32个分片未来最多可扩展到32个物理节点，最优可支持扩容到3.2亿的用户数；","tags":[{"name":"分布式","slug":"分布式","permalink":"https://dongweizhao.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"分库分表及事务一致性设计","slug":"分库分表及事务一致性设计","permalink":"https://dongweizhao.github.io/tags/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E5%8F%8A%E4%BA%8B%E5%8A%A1%E4%B8%80%E8%87%B4%E6%80%A7%E8%AE%BE%E8%AE%A1/"}]},{"title":"01 分库分表的产生背景","date":"2020-06-29T03:19:49.000Z","path":"2020/06/29/2022/数据库中间件/分库分表的产生背景/","text":"产生背景单一DB 如图所示，这是单一DB的应用架构，db中主要包括三种业务类型的表，分表是用户、订单、商品。 而对应业务操作基本都是在一个应用中完成的，这种架构适合项目周期短、业务简单用户相对不多需求，因为用户量少压力就不是特别大，基本一个DB完全可以支撑 而随着公司的业务规模逐渐扩大，带来的效果就是用户量和业务的复杂度日益增加， 这时这种架构就会出现一系列问题，比如响应过慢，有时候甚至会出现超时。 而通过观察，首先出问题的地方，就是DB这块，以前数据量较少的时候，一个查询操作，会快速返回结果，而现在需要等好长时间，而查询操作过慢也导致了后续其它的操作无法进行，因为数据库的连接数有限，而一个系统的操作基本都是读多写少的操作，所以这时我们思考，能不能把数据库的读操作和其它操作分离开呢，所以就出现了我们读写分离的架构。 读写分离 读写分离的架构就是把我们系统中读操作和写操作分离开，通常写操作的节点叫做Master节点，读操作的节点叫做slave,或者叫做主节点和从节点， 其中从节点可以部署多个，来分摊读取数据的压力。看似是一个完美的解决方案，但是也带来一些问题 读取数据的准确性 在以前的单一DB的架构中，因为读操作和写操作，都在一个节点不会出现此问题，而这种架构读取的数据是通过主节点同步到从节点，而同步是需要花费时间的，而这块时间也会受到一系列的因素影响，有时会变的 并没有那么快，比如网络抖动等。一般正常都是毫秒级的 ，所以如果对数据实时性要求比较高的，还是需要走主节点的。 多数据源的管理 单一的DB架构中，一个数据源就可以完全搞定，现在我们程序中需要配置多个数据源来进行操作数据，而且还要区分读操作和写操作，不过市场上也有一些开源的读写分离的中间件来解决此问题。 以上两个问题解决了，系统是完全可以支撑现有业务操作的，但是一个公司业务在飞速发展，数据量还在不断增大，到一定的时间我们就会遇到第三个问题 数据量持续增大1231. 读节点不管增加多个，响应还是比较慢。2. 写操作也比较耗时，往往更新一条数据。3. DB的CPU使用率内存、CPU使用率持续增加。 这时候我们分析，我们DB中表主要由用户、订单、商品组成，能不能把这三快单独放在单独的DB中，这样我们DB的数据量就会下去。 同时我们发现这种切分的，应用层面也可以切分出来了，分为用户系统、订单系统、商品，因为以前所有的表都在一个DB中，系统层面也就没分，其实开发早希望分了， 因为随着业务复杂度变高 应用本身代码量交大，依赖第三方包也越来越多，全量编译、打包部署时间会大大加长，如果功能出错，需要重新操作。 由于业务快速发展，不同小组负责不同业务模块，但是又没有服务契约这种约定，公共的功能都是本地api的提供，因此会造成公共功能重复开发。 通过以上问题所以引申出了我们垂直切分架构。 垂直切分 把系统中表按照业务分类，放在单独DB中，也就把数据或者分摊到不同的DB中 如图所示数据库分为用户、订单、商品库，来分摊以前单一DB所面临的压力，同时在配置上读写分离的话，是可以支撑更多的请求访问的。 但是引入一个新的架构解决问题的同时，也会带来其它的一些问题，垂直切分所带来的问题 分布式事务的问题 多个系统进行调用的 以前在单一DB架构时，同一个事务中操作了用户和商品的表，现在不在同一个库中，并且应用系统现在也不在一起，所以需要拆分出来，以服务的方式进行调用，这种会带来分布式事务的问题。 多个库中表操作 假如应用系统没有拆分，只是数据库进行了拆分，以前同一个事务中操作的表现在在多个库中，这种也会产生分布式事务问题。 跨库join的问题以前的连表查询的语句涉及的表，现在可能不在一个库中，那么需要进行拆分出来单独调用或者找有没有单独解决此类问题的中间件来解决。 以上问题在业务上规避或者通过程序改造完成了，看似是没什么问题了，就这样以这种架构运行了一段时间。 突然有一天产品投诉说，系统中一些操作很慢，比如商品查询，好友关系的查询，我们排查发现这几张表的数据已经有2千万了，此时无论是写入还是读取都是一个很耗时的操作。如果能把这些表的数据切分到不同库中，就可以解决此问题，所以就产生出了，水平切分这样一种架构。 水平切分 把表的某个字段用某种规则来分散到多个库之中,每个表中包含一部分数据。简单来说,我们可以将数据的水平切分理解为是按照数据行的切分,就是将表中的某些行切分到一个数据库,而另外的某些行又切 分到其他的数据库中 如图所示为水平切分的架构图，通过对原有用户、订单、商品库中部分表进行了切分，把压力分摊到多个库中。其中以用户库为例，来说明水平切分大致的原则，首先对库中的表进行梳理，主要分为两大类: 基础参数的相关表1如业务参数、安全问题相关表，此类表的特点是数据量不是特别大，所以不需要水平切分。 用户相关表1此类表会随着时间的推进，表的数据会越来越大，所以需要针对这些表进行水平切分。 所以对用户库切分至3个库，分别分片库2个，基础库1个。 那水平切分有哪些问题呢，主要有以下几点： 多数据源的问题此类问题在读写分离也会遇到，只是比以前更加复杂，以前的读写分离只需要区分读和写操作。而水平切分更加复杂，水平切分根据表的分片规则进行计算，来决定去哪个库中操作，从而在判断操作的类型，在获取对应库中读数据源或者写数据源。 数据聚合的问题以前查询一张表的操作，需要到单个数据源去获取就可以查询出所有的数据，水平切分后，需要到多个库中进行获取操作，然后聚合才能完成。复杂度越来越高了。 高并发下原子性的问题以前用户的信息都在一张表中进行存储，多个用户进行注册时，输入相同的用户名，在进行数据保存时，数据库会进行唯一值判断，那么只有一个用户的数据能保存成功，这样就保证了数据的原子性。 水平切分后，多个用户注册的信息，可能不在一个库中，因为大多数切分的字段是用户ID，不同用户ID会存在在多个库中，那么就无法进行唯一值的判断 ，所有就会产生多条相同的用户名的数据。从而导致一系列问题。 如果解决以上问题，那么就可以安心使用水平切分这种架构了，但是逐渐还会遇到一些问题，如每个节点数据还会达到的瓶颈等，具体怎么做，后续章节会有介绍。","tags":[{"name":"分布式","slug":"分布式","permalink":"https://dongweizhao.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"分库分表及事务一致性设计","slug":"分库分表及事务一致性设计","permalink":"https://dongweizhao.github.io/tags/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E5%8F%8A%E4%BA%8B%E5%8A%A1%E4%B8%80%E8%87%B4%E6%80%A7%E8%AE%BE%E8%AE%A1/"}]},{"title":"链表数据翻转","date":"2018-02-11T03:29:56.000Z","path":"2018/02/11/2022/java/链表数据翻转/","text":"123456789101112131415161718192021222324252627282930313233/** * Created by dongweizhao on 2018/2/11. * 对链表数据进行翻转,如:1-2-3-4-5 翻转后 5-4-3-2-1 */public class LinkedListReverse &#123; public static class ListNode &#123; int val; ListNode next; ListNode(int val) &#123; this.val = val; this.next = null; &#125; &#125; public ListNode reverse(ListNode head) &#123; if (head == null) return head; ListNode node = null; for (; head != null; head = head.next) &#123; if (node == null) &#123; node = new ListNode(head.val); &#125; else &#123; ListNode n = node; node = new ListNode(head.val); node.next = n; &#125; &#125; return node; &#125;&#125;","tags":[{"name":"链表","slug":"链表","permalink":"https://dongweizhao.github.io/tags/%E9%93%BE%E8%A1%A8/"}]},{"title":"链表的数据两两交换","date":"2018-02-11T03:25:12.000Z","path":"2018/02/11/2022/数据库中间件/链表的数据两两交换/","text":"链表（单向&#x2F;双向）的数据两两交换算法实现，例如:1-&gt;2-&gt;3-&gt;4-&gt;5 交换后 2-&gt;1-&gt;4-&gt;3-&gt;5 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167package com.algorithm;/** * 链表的数据两两交换, * 例如:1-&gt;2-&gt;3-&gt;4-&gt;5 交换后 2-&gt;1-&gt;4-&gt;3-&gt;5 */public class LinkedListSwap &#123; /** * 双向链表节点 */ public static class Node &#123; private Node prev; private int val; private Node next; public Node(Node prev, Node next) &#123; this.prev = prev; this.next = next; &#125; public Node(int val, Node next) &#123; this.val = val; this.next = next; &#125; public Node(Node prev, int val, Node next) &#123; this.prev = prev; this.val = val; this.next = next; &#125; public Node(int val) &#123; this.val = val; &#125; public Node() &#123; &#125; public int getVal() &#123; return val; &#125; public void setVal(int val) &#123; this.val = val; &#125; public Node getNext() &#123; return next; &#125; public void setNext(Node next) &#123; this.next = next; &#125; public Node getPrev() &#123; return prev; &#125; public void setPrev(Node prev) &#123; this.prev = prev; &#125; &#125; /** * 单向链表 */ public static class Node2 &#123; private int val; private Node2 next; public Node2(int val) &#123; this.val = val; &#125; public Node2(int val, Node2 next) &#123; this.val = val; this.next = next; &#125; public int getVal() &#123; return val; &#125; public void setVal(int val) &#123; this.val = val; &#125; public Node2 getNext() &#123; return next; &#125; public void setNext(Node2 next) &#123; this.next = next; &#125; &#125; public static void main(String[] args) &#123; /**双向链表测试**/ Node node1 = new Node(1); Node node2 = new Node(2); Node node3 = new Node(3); Node node4 = new Node(4); Node node5 = new Node(5); node1.setNext(node2); node2.setPrev(node1); node2.setNext(node3); node3.setPrev(node2); node3.setNext(node4); node4.setPrev(node3); node4.setNext(node5); node5.setPrev(node4); LinkedListSwap demo1 = new LinkedListSwap(); Node n = demo1.swap(node1); /** 单项链表测试 **/ Node2 n5 = new Node2(5); Node2 n4 = new Node2(4, n5); Node2 n3 = new Node2(3, n4); Node2 n2 = new Node2(2, n3); Node2 n1 = new Node2(1, n2); Node2 temp = demo1.swap2(n1); &#125; /** * 双向链表交换 * * @param node * @return */ public Node swap(Node node) &#123; int i = 0; Node n; for (n = node; node.next != null; node = node.next) &#123; if (++i % 2 == 0) &#123; Node prev = node.prev; int prevVal = prev.getVal(); prev.setVal(node.getVal()); node.setVal(prevVal); &#125; &#125; return n; &#125; /** * 单向链表交换 * * @param node * @return */ public Node2 swap2(Node2 node) &#123; int i = 0; Node2 n; Node2 prev = null; for (n = node; node.next != null; node = node.next) &#123; if (++i % 2 == 0) &#123; int prevVal = prev.getVal(); prev.setVal(node.getVal()); node.setVal(prevVal); &#125; else &#123; prev = node; &#125; &#125; return n; &#125;&#125;","tags":[{"name":"链表","slug":"链表","permalink":"https://dongweizhao.github.io/tags/%E9%93%BE%E8%A1%A8/"}]},{"title":"Buffer剖析","date":"2018-01-26T02:08:10.000Z","path":"2018/01/26/2022/java/Buffer/","text":"Buffer 类是 java.nio 的构造基础。一个 Buffer 对象是固定数量的数据的容器，其作用是一个存储器，或者分段运输区，在这里，数据可被存储并在之后用于检索。缓冲区可以被写满或释放。对于每个非布尔原始数据类型都有一个缓冲区类，即 Buffer 的子类有：ByteBuffer、CharBuffer、DoubleBuffer、FloatBuffer、IntBuffer、LongBuffer 和 ShortBuffer，是没有 BooleanBuffer 之说的。尽管缓冲区作用于它们存储的原始数据类型，但缓冲区十分倾向于处理字节。非字节缓冲区可以在后台执行从字节或到字节的转换，这取决于缓冲区是如何创建的。 属性容量(Capacity) 缓冲区能够容纳的数据元素的最大数量。这一容量在缓冲区创建时被设定，并且永远不能被改变 上界(Limit) 缓冲区的第一个不能被读或写的元素。缓冲创建时，limit 的值等于 capacity 的值。假设 capacity &#x3D; 1024，我们在程序中设置了 limit &#x3D; 512，说明，Buffer 的容量为 1024，但是从 512 之后既不能读也不能写，因此可以理解成，Buffer 的实际可用大小为 512。 位置(Position) 下一个要被读或写的元素的索引。位置会自动由相应的 get() 和 put() 函数更新。 这里需要注意的是positon的位置是从0开始的。 标记(Mark) 一个备忘位置。标记在设定前是未定义的(undefined)。使用场景是，假设缓冲区中有 10 个元素，position 目前的位置为 2(也就是如果get的话是第三个元素)，现在只想发送 6 - 10 之间的缓冲数据，此时我们可以 buffer.mark(buffer.position())，即把当前的 position 记入 mark 中，然后 buffer.postion(6)，此时发送给 channel 的数据就是 6 - 10 的数据。发送完后，我们可以调用 buffer.reset() 使得 position &#x3D; mark，因此这里的 mark 只是用于临时记录一下位置用的。 方法flip() flip方法将Buffer从写模式切换到读模式。调用flip()方法会将position设回0，并将limit设置成之前position的值,这样就可以读取之前所有写入的数据 123456public final Buffer flip() &#123; limit = position; position = 0; mark = -1; return this;&#125; 示例 123ByteBuffer buffer = ByteBuffer.allocate(1024); buffer.put((byte)&#x27;H&#x27;).put((byte)&#x27;e&#x27;).put((byte)&#x27;l&#x27;).put((byte)&#x27;l&#x27;).put((byte)&#x27;o&#x27;); 此时，position &#x3D; 5，limit &#x3D; capacity &#x3D; 1024。现在我们要从正确的位置从 buffer 读数据，我们可以把 position 置为 0，那么字符串的结束位置在哪呢？这里上界该出场了。如果把上界设置成当前 position 的位置，即 5，那么 limit 就是结束的位置。上界属性指明了缓冲区有效内容的末端。人工实现翻转： 1buffer.limit(buffer.position()).position(0); 但系统提供了一个非常便利的函数：buffer.flip()。另外， rewind() rewind() 函数与 flip() 相似，但不影响上界属性，它只是将位置值设回 0。在进行buffer读操作的时候，一般都会使用buffer.flip()函数。 hasRemaining() 读取缓冲区时告诉你是否已经达到缓冲区的上界 示例 123for (int i = 0; buffer.hasRemaining(); i++) &#123; myByteArray[i] = buffer.get(); &#125; 很明显，上面的代码，每次都要判断元素是否到达上界。我们可以做：改变后的读取过程 1234int count = buffer.hasRemaining(); for (int i = 0; i &lt; count; i++) &#123; myByteArray[i] = buffer.get(); &#125; 清空缓冲区clear() clear() 函数将缓冲区重置为空状态。它并不改变缓冲区中的任何数据元素，而是仅仅将 limit 设为容量的值，并把 position 设回 0，如果这会在写入元素的话，会覆盖原有索引位置的元素 123456public final Buffer clear() &#123; position = 0; limit = capacity; mark = -1; return this;&#125; Compact() compact()方法只会清除已经读过的数据示例： 1234567891011121314151617181920212223242526 @Test public void compactTest() &#123; ByteBuffer buffer = ByteBuffer.allocate(10); buffer.put((byte) &#x27;M&#x27;).put((byte) &#x27;e&#x27;).put((byte) &#x27;l&#x27;).put((byte) &#x27;l&#x27;).put((byte) &#x27;o&#x27;).put((byte) &#x27;w&#x27;); //进行翻转,切换为读模式 buffer.flip(); System.out.println((char) buffer.get()); buffer.compact(); System.out.println(&quot;-------&quot;); buffer.put((byte) &#x27;s&#x27;); buffer.flip(); while (buffer.hasRemaining()) &#123; System.out.println((char) buffer.get()); &#125; &#125; 结果： M-------ellows 比较equals() 缓存器类型比对 剩余元素数量比对 如果在比对前,切换为读模式flip(),那么是各元素值比对,否则是默认值比对,永远返回成功。 1234567891011121314151617public boolean equals(Object ob) &#123; if (this == ob) return true; //类型比对 if (!(ob instanceof ByteBuffer)) return false; //剩余元素数量比对 ByteBuffer that = (ByteBuffer)ob; if (this.remaining() != that.remaining()) return false; int p = this.position(); for (int i = this.limit() - 1, j = that.limit() - 1; i &gt;= p; i--, j--) //剩余元素默认值比对 if (!equals(this.get(i), that.get(j))) return false; return true; &#125; compareToTest() 比较剩余未读取的元素值,返回0 表示 如果所有元素值都相等,在比较剩余,那个byte首先被读取完,即:即:(limit - postion),是否相等 存取元素get(byte[] dst) 读取buffer数据至dst数组，如果buffer中的元素不能够填满dst，则抛出BufferUnderflowException get(byte[] dst, int offset, int length) 读取buffer数据至dst，offer为dst存放起始位置，length为获取几个元素，如果buffer中的元素数量小于length（即不能够满足dst需要的元素数量），则抛出BufferUnderflowException put(byte [] src) 从src数组的起始位置，读取所有元素至buffer，如果要写入的元素的数量大于buffer的可写入数量，则抛出throw new BufferOverflowException(); put(byte[] src, int offset, int length) { 从src数组中读取数据至buffer,offer的起始位置，length为从offer开始读取元素的数量，如果要length大于buffer的可写入数量，则抛出throw new BufferOverflowException(); 创建缓冲区allocate (int capacity) allocate操作创建一个缓冲区对象，是由系统自动创建一个长度为capacity的数组 123456789101112public static ByteBuffer allocate(int capacity) &#123; if (capacity &lt; 0) throw new IllegalArgumentException(); return new HeapByteBuffer(capacity, capacity); &#125; HeapByteBuffer(int cap, int lim) &#123; // package-private //自动创建一个length为cap的数组 super(-1, 0, lim, cap, new byte[cap], 0); &#125; wrap(byte[] array) wrap操作创建一个缓冲区对象，但不分配任何空间来储存数据元素。它使用提供的数组作为存储空间来储存缓冲区中的数据元素。 1234567891011121314public static ByteBuffer wrap(byte[] array) &#123; return wrap(array, 0, array.length); &#125; public static ByteBuffer wrap(byte[] array, int offset, int length)&#123; try &#123; return new HeapByteBuffer(array, offset, length); &#125; catch (IllegalArgumentException x) &#123; throw new IndexOutOfBoundsException(); &#125;&#125; wrap(byte[] array, int offset, int length) 与wrap(byte[] array)方法一样，只是创建一个 postion为offset，limit为offset+length的缓冲区 12char[] myArray = new char[10];CharBuffer charbuffer = CharBuffer.wrap (myArray, 2, 3); 以上代码将会创建一个position &#x3D; 2, limit &#x3D; 5, capacity &#x3D; 10的Buffer； 复制缓存区以下为复制缓存区的操作方法 123public abstract CharBuffer duplicate(); public abstract CharBuffer asReadOnlyBuffer(); public abstract CharBuffer slice(); duplicate() 创建bytebuffer的浅拷贝,即数据共享,但是position&#x2F;limit&#x2F;cap&#x2F;capacity是相互独立的 12345678ByteBuffer b1 = ByteBuffer.allocate(10);ByteBuffer b2=b1.duplicate();b1.put((byte) &#x27;M&#x27;).put((byte) &#x27;e&#x27;).put((byte) &#x27;l&#x27;).put((byte) &#x27;l&#x27;).put((byte) &#x27;o&#x27;).put((byte) &#x27;w&#x27;);b1.flip();while (b1.hasRemaining())&#123; assert b1.get()==b2.get();&#125; 上面运行结果会成功，因为b2与b1共享数据 asReadOnlyBuffer() 与duplicate基本相同,只是创建的buffer的是只读,如果进行put元素会抛出ReadOnlyBufferException 123ByteBuffer b1 = ByteBuffer.allocate(10);ByteBuffer b2=b1.asReadOnlyBuffer();b2.put((byte)&#x27;s&#x27;); 运行上面示例，会抛出ReadOnlyBufferException slice() sliece()其实是用于分割缓存区的，该方法创建了一个从原始缓冲区的当前位置开始的新缓冲区，并且其容量是原始缓冲区的剩余元素数量（limit-position)该缓存区与原始缓存区共享一段序列 创建一个容量为10的缓存区ByteBuffer 1ByteBuffer b = ByteBuffer.allocate(10); 修改position&#x3D;2,limit&#x3D;5 1charbuffer1.position(2).limit(5); 调用charbuffer1.slice()方法，对charbuffer1进行分割 1CharBuffer charbuffer2 = charbuffer1.slice(); 此时 charbuffer1：mark &#x3D; -1; position &#x3D; 2; limit &#x3D; 5; capacity &#x3D; 10; charbuffer2：mark &#x3D; -1; position &#x3D; 0; limit &#x3D; 3; capacity &#x3D; 3; 对应源码 123public ByteBuffer slice() &#123; return new HeapByteBuffer(hb,-1, 0,this.remaining(),this.remaining(),this.position() + offset);&#125; 缓冲区视图 byteBuffer类的另外一个常见的使用方式是在一个已有的ByteBuffer类的对象上创建出各种不同的视图。这些视图和它所基于的ByteBuffer类的对象共享同样的存储空间，但是提供额外的实用功能 最常见的ByteBuffer类的视图是转换成对基本数据类型进行操作的缓冲区对象。这些缓冲区包括CharBuffer、ShortBuffer、IntBuffer、LongBuffer、FloatBuffer和DoubleBuffer等Java类。从这些缓冲区的类名就可以知道所操作的数据类型。ByteBuffer类提供了对应的方法来完成相应的转换，如asIntBuffer方法在当前ByteBuffer类的对象的基础上创建一个新的IntBuffer类的视图。新创建的视图和原始的ByteBuffer类的对象所共享的不一定是全部的空间，而只是从ByteBuffer类的对象中的当前读写位置到读写限制之间的可用空间。在这个空间范围内，不论是在ByteBuffer类的对象中还是在作为视图的新缓冲区中，对数据所做的修改，对另一个来说都是可见的。除了数据本身之外，两者的读写位置、读写限制和标记位置等都是相互独立的。 1234567public void viewBuffer() &#123; ByteBuffer buffer = ByteBuffer.allocate(32); buffer.putInt(1); //读取位置为4 IntBuffer intBuffer = buffer.asIntBuffer(); intBuffer.put(2); int value = buffer.getInt(); //值为2 &#125; 直接缓冲区 内核空间（与之相对的是用户空间，如 JVM）是操作系统所在区域，它能与设备控制器（硬件）通讯，控制着用户区域进程（如 JVM）的运行状态。最重要的是，所有的 I&#x2F;O 都直接（物理内存）或间接（虚拟内存）通过内核空间。 从图中你可能会觉得，把数据从内核空间拷贝到用户空间似乎有些多余。为什么不直接让磁盘控制器把数据送到用户空间的缓冲区呢？首先，硬件通常不能直接访问用户空间。其次，像磁盘这样基于块存储的硬件设备操作的是固定大小的数据块，而用户进程请求的可能是任意大小的或非对齐的数据块。在数据往来于用户空间与存储设备的过程中，内核负责数据的分解、再组合工作，因此充当着中间人的角色。 因此，操作系统是在内存区域中进行 I&#x2F;O 操作。这些内存区域，就操作系统方面而言，是相连的字节序列，这也意味着I&#x2F;O操作的目标内存区域必须是连续的字节序列。在 JVM中，字节数组可能不会在内存中连续存储（因为 JAVA 有 GC 机制），或者无用存储单元（会被垃圾回收）收集可能随时对其进行移动。 ​ 出于这个原因，引入了直接缓冲区的概念。直接字节缓冲区通常是 I&#x2F;O 操作最好的选择。非直接字节缓冲区（即通过 allocate() 或 wrap() 创建的缓冲区）可以被传递给通道，但是这样可能导致性能损耗。通常非直接缓冲不可能成为一个本地 I&#x2F;O 操作的目标。 如果你向一个通道中传递一个非直接 ByteBuffer 对象用于写入，通道可能会在每次调用中隐含地进行下面的操作： 创建一个临时的直接 ByteBuffer 对象。 将非直接缓冲区的内容复制到临时直接缓冲区中。 使用临时直接缓冲区执行低层 I&#x2F;O 操作。 临时直接缓冲区对象离开作用域，并最终成为被回收的无用数据。 这可能导致缓冲区在每个 I&#x2F;O 上复制并产生大量对象，而这种事都是我们极力避免的。如果你仅仅为一次使用而创建了一个缓冲区，区别并不是很明显。另一方面，如果你将在一段高性能脚本中重复使用缓冲区，分配直接缓冲区并重新使用它们会使你游刃有余。 直接缓冲区可能比创建非直接缓冲区要花费更高的成本，它使用的内存是通过调用本地操作系统方面的代码分配的，绕过了标准 JVM 堆栈，不受垃圾回收支配，因为它们位于标准 JVM 堆栈之外。 直接 ByteBuffer 是通过调用具有所需容量的 ByteBuffer.allocateDirect() 函数产生的。注意，wrap() 函数所创建的被包装的缓冲区总是非直接的 参考： Java NIO中的缓冲区Buffer（二）创建-复制缓冲区 Buffer类的详解(转)","tags":[{"name":"nio","slug":"nio","permalink":"https://dongweizhao.github.io/tags/nio/"}]},{"title":"线程池的创建与销毁分析","date":"2018-01-17T02:20:20.000Z","path":"2018/01/17/2022/java/线程池分析/","text":"线程池类型 固定线程池(newFixedThreadPool) 指定固定大小线程数，如果执行的任务超过线程数，则添加至阻塞队列中，当线程池线程处理完在从队列中进行获取任务进行处理 1234567public static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(), threadFactory); &#125; 单例线程池(newSingleThreadExecutor) 指定1个线程数，如果执行的任务超过线程数，则添加至阻塞队列中，当线程池线程处理完在从队列中进行获取任务进行处理 1234public static ExecutorService newSingleThreadExecutor(ThreadFactory threadFactory) &#123;return new ThreadPoolExecutor(1, 1,0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;())&#125; 缓存线程池(newCachedThreadPool) 不指定固定线程数，最大线程数为Integer.MAX_VALUE，如果执行的任务超过最大线程数，则添加至阻塞队列中，注意此处用的是SynchronousQueue，表明是如果添加一个任务必须等待处理线程取出，否则不能继续添加任务。 12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; 线程添加1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); //如果当前线程数小于核心线程数，则创建线程 if (workerCountOf(c) &lt; corePoolSize) &#123; //如果创建线程失败，则进行下一步处理 if (addWorker(command, true)) return; c = ctl.get(); &#125; //判断线程池是否在运行，如果是 在试着添加任务到队列中 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125;//否则进行继续尝试创建新线程，如果现有线程数大于最大线程数则返回false else if (!addWorker(command, false)) reject(command);&#125;//删除了不必要的代码private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); for (;;) &#123; int wc = workerCountOf(c); //判断现有线程数是否大于最大线程数 if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // Re-read ctl if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125;&#125; 线程启动1234567891011121314151617181920212223242526272829303132333435363738394041424344454647//删除多余代码private boolean addWorker(Runnable firstTask, boolean core) &#123; boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; final ReentrantLock mainLock = this.mainLock; //创建worker，worker本身也是一个Runnable w = new Worker(firstTask); final Thread t = w.thread; if (t != null) &#123; mainLock.lock(); try &#123; // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int c = ctl.get(); int rs = runStateOf(c); if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); //添加work值workers，后面的运行数统计、关闭线程池都是基于此workers workers.add(w); int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; if (workerAdded) &#123; //启动 t.start(); workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) addWorkerFailed(w); &#125; return workerStarted; &#125; 线程执行任务 当启动线程后，会调用runWorker进行任务的执行，如果当前任务执行完成，则从阻塞队列中进行获取 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try &#123; //先判断当前任务是否不为空，如果不为空则进行当前任务，否则调动getTask()方法，从队列中获取任务 while (task != null || (task = getTask()) != null) &#123; //进行标记表示正在有任务执行，如果这会进行调用shutdown()方法，会判断标记，否则进行中断线程。 w.lock(); // If pool is stopping, ensure thread is interrupted; // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt //如果调用shutdownNow()方法设置stop标记，并且当前线程还未中断，则当前线程自己中断，否则在进行一次判断 if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; //前处理 beforeExecute(wt, task); Throwable thrown = null; try &#123; //执行任务 task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; //后处理 afterExecute(task, thrown); &#125; &#125; finally &#123; task = null; //记录执行完任务数量 w.completedTasks++; //取消正在执行标记 w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; //线程退出，这步只有调用shutdown（）、shutdownNow（）才会执行，否则会在getTask()任务阻塞。 processWorkerExit(w, completedAbruptly); &#125; &#125; 线程池伸缩123456789101112131415161718192021222324252627282930313233343536373839404142private Runnable getTask() &#123; boolean timedOut = false; // Did the last poll() time out? retry: for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123; decrementWorkerCount(); return null; &#125; boolean timed; // Are workers subject to culling? for (;;) &#123; int wc = workerCountOf(c); timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; if (wc &lt;= maximumPoolSize &amp;&amp; ! (timedOut &amp;&amp; timed)) break; //如果当前线程数大于核心线程数或者设置核心线程数容许超时，那么对现有线程池的线程进行回收 if (compareAndDecrementWorkerCount(c)) return null; c = ctl.get(); // Re-read ctl if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; try &#123; Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) return r; timedOut = true; &#125; catch (InterruptedException retry) &#123; timedOut = false; &#125; &#125; &#125; 线程池销毁停止线程池 调用此方法后，不接受新任务，但是会保证线程池中任务执行完(包括队列中的任务),在进行停止 12345678910111213141516public void shutdown() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; checkShutdownAccess(); //设置状态 advanceRunState(SHUTDOWN); //遍历所有未执行任务的线程，对其设置中断 interruptIdleWorkers(); onShutdown(); // hook for ScheduledThreadPoolExecutor &#125; finally &#123; mainLock.unlock(); &#125; //在此判断所有任务都已退出，如果退出则设置标记 “TERMINATED” tryTerminate();&#125; 立即停止线程池 不用等待正在进行任务执行完，立即停止 12345678910111213141516171819202122232425262728293031323334public List&lt;Runnable&gt; shutdownNow() &#123; List&lt;Runnable&gt; tasks; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; checkShutdownAccess(); //设置状态STOP状态 advanceRunState(STOP); ////遍历所有任务的线程(包括正在执行任务的线程)，对其设置中断 interruptWorkers(); //返回等待执行的任务列表 tasks = drainQueue(); &#125; finally &#123; mainLock.unlock(); &#125; //在此判断所有任务都已退出，如果退出则设置标记 “TERMINATED” tryTerminate(); return tasks; &#125; private List&lt;Runnable&gt; drainQueue() &#123; BlockingQueue&lt;Runnable&gt; q = workQueue; List&lt;Runnable&gt; taskList = new ArrayList&lt;Runnable&gt;(); //尝试把队列中任务移动taskList q.drainTo(taskList); //这一步判断主要针对DelayQueue，因为drainTo只返回到期的任务，所以需要单独处理 if (!q.isEmpty()) &#123; for (Runnable r : q.toArray(new Runnable[0])) &#123; if (q.remove(r)) taskList.add(r); &#125; &#125; return taskList; &#125;","tags":[{"name":"并发","slug":"并发","permalink":"https://dongweizhao.github.io/tags/%E5%B9%B6%E5%8F%91/"},{"name":"java","slug":"java","permalink":"https://dongweizhao.github.io/tags/java/"}]},{"title":"03 数据存储与划分原则","date":"2018-01-04T13:56:09.000Z","path":"2018/01/04/2022/数据库中间件/数据存储与划分原则/","text":"前两节对分库分表和遇到一些问题进行解释和总结，本节对分库分表的数据存储和划分原则进行一个讲解 数据存储分别是： 独立存储+缓存：适用于数据量少，基本不变的数据； 读写分离 ： 适用于数据量适中，增长平缓，读多写少的数据 水平切分： 适用于数据量大，增长快速，读写频繁的数据 划分原则 能不分就不分，当单表记录达到一定数量级（&gt;1000万）之后才考虑进行水平切分处理； 分片字段取决于最频繁的查询SQL，选择合适的切分规则，避免跨库聚合，跨库事务； 分片数量尽量少，分片尽量均匀分布在多个 DataHost 上，一个查询 SQL 跨分片越多，则总体性能越差； 考虑数据的增长模式，数据的访问模式，分片关联性能问题，分片扩容问题； 分片表要避免不带任何where条件的查询； 分片规则下面对常用的分片进行一个介绍 范围约定 优点：此分片规则在扩容时只需要添加节点，指定日期范围，可以避免扩容时的数据迁移, 例如：表test规划了两个节点分别为db1、db2，db1存储2015.12之前的数据，db2存储2016.1-2016.6的数据，当时间达到2016.6以后，现有分片规则无法满足，所以就面临分片的增加，一般分片的增加需要进行数据迁移，而基于范围的分片规则，只需增加2016.7 -2016.12即可，不需要对以前的数据进行迁移。 缺点：负载不均衡 如2015.12以前这个业务发展不是特别快，数据量相对不大，但是以后随着营销和推广，业务飞速发展，那么2016.1-2016.6这个节点数据量就相对比较大。 取模 根据分片键的值进行hash，并根据节点数进行取余 优点：负载均衡 缺点：在扩容时需要全量迁移 一致性Hash 按照常用的hash算法来将对应的key哈希到一个具有2^32次方个桶的空间中，即0~(2^32)-1的数字空间中。现在我们可以将这些数字头尾相连，想象成一个闭合的环形. 首先求出数据库节点的哈希值，并将其配置到0-2^32圆上，如 Hash(NODE1) &#x3D; KEY1&#x3D;2^10; Hash(NODE2) &#x3D; KEY2&#x3D;2^20; Hash(NODE3) &#x3D; KEY3&#x3D;2^30; 然后采用同样的方法求出存储数据的键的哈希值，并映射到相同的圆上。 然后从数据映射到的位置开始顺时针查找，将数据保存到找到的第一个服务器上。如果超过2^32仍然找不到服务器，则从0开始查找。 示例： 根据用户ID分片，流水号规则为UR+12位序号,如UR000000000013, 进行hash计算为2^5，则属于NODE1 优点：负载相对均衡 缺点：在扩容时需要部分迁移 ​","tags":[{"name":"分布式","slug":"分布式","permalink":"https://dongweizhao.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"分库分表及事务一致性设计","slug":"分库分表及事务一致性设计","permalink":"https://dongweizhao.github.io/tags/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E5%8F%8A%E4%BA%8B%E5%8A%A1%E4%B8%80%E8%87%B4%E6%80%A7%E8%AE%BE%E8%AE%A1/"}]},{"title":"02 分库分表带来的挑战","date":"2018-01-04T13:55:54.000Z","path":"2018/01/04/2022/数据库中间件/分库分表带来的挑战/","text":"上一节介绍了分库分表的的产生背景，以及遇到的一些问题，本节对上节遇到问题进行一个总结并给出一些解决方案。 问题列表引入分布式事务的问题跨节点join的问题跨节点排序分页的问题高并发下原子性的问题以上是对分库分表遇到一些问题进行了汇总，下面对这些问题以及对应的解决方案一一讲解。 引入分布式事务的问题同一应用系统-引入分布式事务的问题 如图所示，这是一个注册操作步骤，注册服务由两个原子服务组成，分别为： 登录标识原子服务 认证信息原子服务。 其中登录标识对应的登录标识表对应分片键为登录标识，因为为了快速登录，所以不会以用户ID作为分片键。认证信息原子服务对应的分片键为用户ID，那么这种流程，就会引发分布式事务问题，那么针对此类场景是怎么解决。 同一应用系统-分布式事务解决方案 以上为注册服务的注册流程，首先调用登录标识原子服务，如果处理成功，则调用认证信息原子服务，如果失败则返回。 假如处理成功，并调用了认证信息原子服务，此时成功，则流程注册完成，给前端返回结果。 如果操作失败，那么就需要调用冲正服务，对第一步登录标识进行删除，一般情况都会成功，如果遇到极端情况，假如数据库down机，这会推送异常消息至监控平台进行报警，从而人为介入解决。 多系统交互-分布式事务问题上图所示，为开户服务操作步骤，涉及到三个系统。 通过分析，如果采用上篇介绍的方案同步调用，那么会使处理时间拉长，对客户体验不好，同时系统处理能力也会下降。 如果在调用环节中有一个系统出现问题，就会导致各系统中数据状态不一致，而如果采用上篇介绍的冲正方案，处理时间会更加长，从而导致超时，那么针对此类问题，一般是基于消息最终一致性来解决的。 分布式事务解决方案-基于消息的最终一致性我们知道分布式系统中的CAP理论，分别为 Consistency(一致性), 数据一致更新，所有数据变动都是同步的 Availability(可用性), 好的响应性能 Partition tolerance(分区容错性) 可靠性 任何分布式系统只可同时满足二点，没法三者兼顾。如果满足一致性，那么就需要在可用性和分区容错性，做出选择。 如果选择可用性，也就需要避免分区容错性的发生，那么需要将所有事务相关的东西都放在一台机器上，也就说把开户设计的表全部放在一个库中，由一个系统完成。这种情况下虽然分区容错性的可以避免，但是我们系统从分布式系统退化成了单机系统，从根本上失去了扩展性。 如果选择分区容错，一旦遇到分区事件，受影响的服务需要等待数据一致，因此等待期间，无法对外提供服务。而一个系统如果对外提供不了服务，是非常重大的事故，所以是不能接受的。 那么有什么方法，能解决这些问题呢，eBay架构师源于对大规模分布式系统的实践总结，在ACM上发表了BASE理论，BASE理论是指 Basically Available（基本可用） Soft state（软状态） Eventually consistent（最终一致性） BASE理论是对CAP的延伸，核心思想是即使无法做到强一致性，但应用可以采取适当的方式来达到最终一致性。 我们这里分享的基于消息中间件的处理方式，就是最终一致性的体现。如图所示，假如这里A系统为电子账户系统，B系统为客户信息系统，A系统开立电子账户后，保存需要发送消息的数据至消息发送表中，并提交事务后发送至MQ，本次交易就完成了。 剩下的操作由MQ推送至客户信息系统或者客户合约系统，这里以客户信息系统为例，系统拿到消息后，进行数据保存，保存成功，并调用MQ的签收操作，同时拿到此消息进行客户等级升级操作，如果操作失败，那么会有定时检查任务，检查消息消费状态，并进行调起，再次进行升级操作。 因为这种方式是有一定延时，所以业务上要多做一些考量，从而不影响客户体验。 跨节点Join的问题1-解决方案 以上是一个联表查询中，以一张关联表的分片键做为查询条件的场景，那么针对此类场景解决方案，就是拆分为多步。 根据分片键获取到对应另一张表的分片键。 根据返回分片键查询另一张表的数据。 对多张表的结果进行聚合。 这样跨节点join的问题就解决了。 跨节点Join的问题2-解决方案 以上是一个联表查询中，是没有分片键做为查询条件的场景，那么针对此类场景解决方案，也是拆分为单表的查询语句，并进行并行调用，同时从多个节点进行获取，然后在进行聚合。 注意，如果关联的表比较多，不建议所有的表都进行并行调用，因为这样很占数据库的连接数，可以采用以下方式操作，例如：首先拆分多个表语句，然后第一条语句并行访问，获取结果，并根据结果获取到关联表的分片键，在进行数据获取，最后在进行多张表的结果聚合 跨节点排序分页的问题 test表有数据[1,2,3,4,5,6,7,8]，在单库的时候，查询第2页数据并且显示2条，语句是这样的 1select * from test order by id limit 2,2; 数据返回[3,4],但是数据切分以后，如果要查询，这样语句就可能就会有问题，例如：在节点1执行此语句，返回[5,7],节点2返回[6,8],然后在进行排序，返回了[5,6],所以结果就不准确了，所以应该对sql语句改写为: 1select * from test order by id limit 0,4; 然后在根据各节点返回的数据，在进行排序，筛选出第2页的2条。 这种有什么问题呢， 每个节点返回更多的数据，增大了网络传输量 服务层还需要进行二次排序，增大了服务层的计算量 随着页码的增大，性能会急剧下降 所以开发时，应尽量避免这种需求，以其它的方式来满足，如果非要实现，可以采用业务折中的方式，如静止跳页 1select * from test where id&gt;0 limit 2; 根据id值进行排序，返回对应的条数，在内存中对各个节点返回的数据进行排序，得到需要的数据，相比以前的方案，貌似跟以前处理流程一样，但是在查询第二页时，根据上一页的id的最大值id_max,作为第二页的最小值，会将 1select * from test order by id limit 2,2; 改写成： 1select * from test order by id&gt; $id_max limit 2 这样每个节点不用返回4页数据了，只需要返回跟第一页一样页数的数据，可以看到通过对业务的折中，性能得到大大的提升。 高并发下多节点原子性问题如上图所以，这种一个实名认证的交易场景，实名认证成功则插入到对应的客户表中，客户表分片键为用户ID,身份证是唯一索引，但是它只能保证在单个节点的唯一性，不能保证多个节点的唯一性，所以以上场景有可能会插入两条重复的数据。 为了解决保证多个节点的数据的唯一性，可以通过分布式锁来解决，redis、zookeeper都有提供分布式锁的功能如上图，在进行认证时，首先登记身份证号至redis,如果缓存中没有此身份证则登记成功，在进行下一步操作，否则失败。","tags":[{"name":"分布式","slug":"分布式","permalink":"https://dongweizhao.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"分库分表及事务一致性设计","slug":"分库分表及事务一致性设计","permalink":"https://dongweizhao.github.io/tags/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E5%8F%8A%E4%BA%8B%E5%8A%A1%E4%B8%80%E8%87%B4%E6%80%A7%E8%AE%BE%E8%AE%A1/"}]},{"title":"阿姆达尔定律","date":"2018-01-04T01:46:51.000Z","path":"2018/01/04/2022/java/Amdahl/","text":"原文地址 作者：Jakob Jenkov 译者：张坤 阿姆达尔定律可以用来计算处理器平行运算之后效率提升的能力。阿姆达尔定律因Gene Amdal 在1967年提出这个定律而得名。绝大多数使用并行或并发系统的开发者有一种并发或并行可能会带来提速的感觉，甚至不知道阿姆达尔定律。不管怎样，了解阿姆达尔定律还是有用的。 我会首先以算术的方式介绍阿姆达尔定律定律，然后再用图表演示一下。 阿姆达尔定律定义一个程序（或者一个算法）可以按照是否可以被并行化分为下面两个部分： 可以被并行化的部分 不可以被并行化的部分 假设一个程序处理磁盘上的文件。这个程序的一小部分用来扫描路径和在内存中创建文件目录。做完这些后，每个文件交个一个单独的线程去处理。扫描路径和创建文件目录的部分不可以被并行化，不过处理文件的过程可以。 程序串行（非并行）执行的总时间我们记为T。时间T包括不可以被并行和可以被并行部分的时间。不可以被并行的部分我们记为B。那么可以被并行的部分就是T-B。下面的列表总结了这些定义： T &#x3D; 串行执行的总时间 B &#x3D; 不可以并行的总时间 T- B &#x3D; 并行部分的总时间 从上面可以得出： T &#x3D; B + (T – B) 首先，这个看起来可能有一点奇怪，程序的可并行部分在上面这个公式中并没有自己的标识。然而，由于这个公式中可并行可以用总时间T 和 B（不可并行部分）表示出来，这个公式实际上已经从概念上得到了简化，也即是指以这种方式减少了变量的个数。 T- B 是可并行化的部分，以并行的方式执行可以提高程序的运行速度。可以提速多少取决于有多少线程或者多少个CPU来执行。线程或者CPU的个数我们记为N。可并行化部分被执行的最快时间可以通过下面的公式计算出来： (T – B ) &#x2F; N 或者通过这种方式 (1 &#x2F; N) * (T – B) 维基中使用的是第二种方式。 根据阿姆达尔定律，当一个程序的可并行部分使用N个线程或CPU执行时，执行的总时间为： T(N) &#x3D; B + ( T – B ) &#x2F; N T(N)指的是在并行因子为N时的总执行时间。因此，T(1)就执行在并行因子为1时程序的总执行时间。使用T(1)代替T，阿姆达尔定律定律看起来像这样： T(N) &#x3D; B + (T(1) – B) &#x2F; N 表达的意思都是是一样的。 一个计算例子为了更好的理解阿姆达尔定律，让我们来看一个计算的例子。执行一个程序的总时间设为1.程序的不可并行化占40%，按总时间1计算，就是0.4.可并行部分就是1 – 0.4 &#x3D; 0.6. 在并行因子为2的情况下，程序的执行时间将会是： 1234T(2) = 0.4 + ( 1 - 0.4 ) / 2 = 0.4 + 0.6 / 2 = 0.4 + 0.3 = 0.7 在并行因子为5的情况下，程序的执行时间将会是： 1 &#96;&#96; 1234T(5) = 0.4 + ( 1 - 0.4 ) / 5 = 0.4 + 0.6 / 6 = 0.4 + 0.12 = 0.52 阿姆达尔定律图示为了更好地理解阿姆达尔定律，我会尝试演示这个定定律是如何诞生的。 首先，一个程序可以被分割为两部分，一部分为不可并行部分B，一部分为可并行部分1 – B。如下图： 在顶部被带有分割线的那条直线代表总时间 T(1)。 下面你可以看到在并行因子为2的情况下的执行时间： 并行因子为3的情况： 优化算法从阿姆达尔定律可以看出，程序的可并行化部分可以通过使用更多的硬件（更多的线程或CPU）运行更快。对于不可并行化的部分，只能通过优化代码来达到提速的目的。因此，你可以通过优化不可并行化部分来提高你的程序的运行速度和并行能力。你可以对不可并行化在算法上做一点改动，如果有可能，你也可以把一些移到可并行化放的部分。 优化串行分量如果你优化一个程序的串行化部分，你也可以使用阿姆达尔定律来计算程序优化后的执行时间。如果不可并行部分通过一个因子O来优化，那么阿姆达尔定律看起来就像这样： 1T(O, N) = B / O + (1 - B / O) / N 记住，现在程序的不可并行化部分占了B / O的时间，所以，可并行化部分就占了1 - B / O的时间. 如果B为0.4，O为2，N为5，计算看起来就像这样： 123456T(2,5) = 0.4 / 2 + (1 - 0.4 / 2) / 5 = 0.2 + (1 - 0.4 / 2) / 5 = 0.2 + (1 - 0.2) / 5 = 0.2 + 0.8 / 5 = 0.2 + 0.16 = 0.36 运行时间 vs. 加速到目前为止，我们只用阿姆达尔定律计算了一个程序或算法在优化后或者并行化后的执行时间。我们也可以使用阿姆达尔定律计算加速比（speedup），也就是经过优化后或者串行化后的程序或算法比原来快了多少。 如果旧版本的程序或算法的执行时间为T，那么增速比就是： 1Speedup = T / T(O , N); 为了计算执行时间，我们常常把T设为1，加速比为原来时间的一个分数。公式大致像下面这样： 1Speedup = 1 / T（O,N) 如果我们使用阿姆达尔定律来代替T(O,N)，我们可以得到下面的公式： 1Speedup = 1 / ( B / O + (1 - B / O) / N) 如果B = 0.4， O = 2， N = 5， 计算变成下面这样： 1234567Speedup = 1 / ( 0.4 / 2 + (1 - 0.4 / 2) / 5) = 1 / ( 0.2 + (1 - 0.4 / 2) / 5) = 1 / ( 0.2 + (1 - 0.2) / 5 ) = 1 / ( 0.2 + 0.8 / 5 ) = 1 / ( 0.2 + 0.16 ) = 1 / 0.36 = 2.77777 ... 上面的计算结果可以看出，如果你通过一个因子2来优化不可并行化部分，一个因子5来并行化可并行化部分，这个程序或算法的最新优化版本最多可以比原来的版本快2.77777倍。 测量，不要仅是计算虽然阿姆达尔定律允许你并行化一个算法的理论加速比，但是不要过度依赖这样的计算。在实际场景中，当你优化或并行化一个算法时，可以有很多的因子可以被考虑进来。 内存的速度，CPU缓存，磁盘，网卡等可能都是一个限制因子。如果一个算法的最新版本是并行化的，但是导致了大量的CPU缓存浪费，你可能不会再使用x N个CPU来获得x N的期望加速。如果你的内存总线（memory bus），磁盘，网卡或者网络连接都处于高负载状态，也是一样的情况。 我们的建议是，使用阿姆达尔定律定律来指导我们优化程序，而不是用来测量优化带来的实际加速比。记住，有时候一个高度串行化的算法胜过一个并行化的算法，因为串行化版本不需要进行协调管理（上下文切换），而且一个单个的CPU在底层硬件工作（CPU管道、CPU缓存等）上的一致性可能更好。 转载自并发编程网 – ifeve.com本文链接地址: 阿姆达尔定律","tags":[{"name":"并发","slug":"并发","permalink":"https://dongweizhao.github.io/tags/%E5%B9%B6%E5%8F%91/"}]},{"title":"hashMap死锁分析","date":"2017-12-30T03:59:38.000Z","path":"2017/12/30/2022/java/hashMap死锁分析/","text":"概述 在hashMap中，当插入的值到达一定的量的时候，hashMap就会进行rehash，进行扩容，那么在扩容的时候就会发生死锁。 扩容条件1234567891011121314151617181920212223public V put(K key, V value) &#123; if (table == EMPTY_TABLE) &#123; inflateTable(threshold); &#125; if (key == null) return putForNullKey(value); int hash = hash(key); int i = indexFor(hash, table.length); for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; addEntry(hash, key, value, i); return null; &#125; 以上为新增元素的put方法，如果新增的元素通过hash计算的索引，在table数组中不存在，那么就会调用addEntry方法 12345678910void addEntry(int hash, K key, V value, int bucketIndex) &#123; if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; resize(2 * table.length); hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); &#125; createEntry(hash, key, value, bucketIndex);&#125; 如果size大于threshold的值（为初始化的值）,则会进行扩容，扩容的大小必须是2的倍数，因为在进行计算索引的时候，会进行位运算 1234567891011121314void resize(int newCapacity) &#123; Entry[] oldTable = table; int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return; &#125; Entry[] newTable = new Entry[newCapacity]; transfer(newTable, initHashSeedAsNeeded(newCapacity)); table = newTable; threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1);&#125; 根据newCapacity创建新的Entry，并做为参数传送给transfer方法，transfer方法，就是把原有table中entry的数据重新进行hash计算，并保存至newTable中，然后table&#x3D;newTable，完成扩容，那么发送死锁的地方就发送在transfer方法中 123456789101112131415void transfer(Entry[] newTable, boolean rehash) &#123; int newCapacity = newTable.length; for (Entry&lt;K,V&gt; e : table) &#123; while(null != e) &#123; Entry&lt;K,V&gt; next = e.next; if (rehash) &#123; e.hash = null == e.key ? 0 : hash(e.key); &#125; int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; &#125; &#125; &#125; 通过前面的介绍，终于到了关键时刻了，下面看看怎么发送的死锁。 假如:table.length&#x3D;2,值为3，7，5,排列如下 扩容后：table.length&#x3D;4，排列如下 但是这个以上排列只是不发送死锁的情况，如果在高并发下场景，会出现不一样的结果。 123456789101112131415void transfer(Entry[] newTable, boolean rehash) &#123; int newCapacity = newTable.length; for (Entry&lt;K,V&gt; e : table) &#123; while(null != e) &#123; Entry&lt;K,V&gt; next = e.next; if (rehash) &#123; e.hash = null == e.key ? 0 : hash(e.key); &#125; int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; &#125; &#125; &#125; 假如： 有线程A、线程B 1Entry&lt;K,V&gt; next = e.next; 当B第一次执行完以下代码，进行了挂起，那么：e&#x3D;3，next&#x3D;7，在B挂起的时，线程A完成了transfer的扩容，那么7.next&#x3D;3，3.next&#x3D;null,扩容后如下图： 接着线程B继续执行，计算e&#x3D;3的index为3，完成第一次循环： 接着进行第二次循环，此时：e&#x3D;7,next&#x3D;3 为啥next&#x3D;3呢？因为在线程A完成扩容后，7的next为3,那么在执行到Entry&lt;K,V&gt; next &#x3D; e.next时，所以next&#x3D;3 接着进行第三次循环，此时：e&#x3D;3，next&#x3D;null,而当执行到&#x3D;&#x3D;e.next &#x3D; newTable[i]&#x3D;&#x3D; 语句时，坑爹的事情发生了，形成闭环了，如下图： 注意此时还没有发送死锁，死锁是在获取元素时产生的，如调用一个不存在的元素，并且index是3，那么恭喜你死锁发生了。","tags":[{"name":"并发","slug":"并发","permalink":"https://dongweizhao.github.io/tags/%E5%B9%B6%E5%8F%91/"},{"name":"java","slug":"java","permalink":"https://dongweizhao.github.io/tags/java/"}]}]